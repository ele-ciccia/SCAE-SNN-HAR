{"trial_data": [["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00021\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032315f32315f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"21_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00021_21_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716734377.3122585,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8450413223140495,\n    \"timestamp\": 1716745751,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00021\",\n    \"date\": \"2024-05-26_19-49-11\",\n    \"time_this_iter_s\": 11374.180362224579,\n    \"time_total_s\": 11374.180362224579,\n    \"pid\": 316306,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11374.180362224579,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"21_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716745751.494381,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8450413223140495,\n      \"min\": 0.8450413223140495,\n      \"avg\": 0.8450413223140495,\n      \"last\": 0.8450413223140495,\n      \"last-5-avg\": 0.8450413223140495,\n      \"last-10-avg\": 0.8450413223140495\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11374.180362224579,\n      \"min\": 11374.180362224579,\n      \"avg\": 11374.180362224579,\n      \"last\": 11374.180362224579,\n      \"last-5-avg\": 11374.180362224579,\n      \"last-10-avg\": 11374.180362224579\n    },\n    \"time_total_s\": {\n      \"max\": 11374.180362224579,\n      \"min\": 11374.180362224579,\n      \"avg\": 11374.180362224579,\n      \"last\": 11374.180362224579,\n      \"last-5-avg\": 11374.180362224579,\n      \"last-10-avg\": 11374.180362224579\n    },\n    \"time_since_restore\": {\n      \"max\": 11374.180362224579,\n      \"min\": 11374.180362224579,\n      \"avg\": 11374.180362224579,\n      \"last\": 11374.180362224579,\n      \"last-5-avg\": 11374.180362224579,\n      \"last-10-avg\": 11374.180362224579\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430821706319940aeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430821706319940aeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c63717161c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c63717161c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c63717161c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c63717161c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c63717161c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c63717161c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00078\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037385f37385f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"78_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00078_78_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717464013.9042895,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.861952861952862,\n    \"timestamp\": 1717469848,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00078\",\n    \"date\": \"2024-06-04_04-57-28\",\n    \"time_this_iter_s\": 5834.733065843582,\n    \"time_total_s\": 5834.733065843582,\n    \"pid\": 602162,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 5834.733065843582,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"78_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717469848.6391406,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.861952861952862,\n      \"min\": 0.861952861952862,\n      \"avg\": 0.861952861952862,\n      \"last\": 0.861952861952862,\n      \"last-5-avg\": 0.861952861952862,\n      \"last-10-avg\": 0.861952861952862\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5834.733065843582,\n      \"min\": 5834.733065843582,\n      \"avg\": 5834.733065843582,\n      \"last\": 5834.733065843582,\n      \"last-5-avg\": 5834.733065843582,\n      \"last-10-avg\": 5834.733065843582\n    },\n    \"time_total_s\": {\n      \"max\": 5834.733065843582,\n      \"min\": 5834.733065843582,\n      \"avg\": 5834.733065843582,\n      \"last\": 5834.733065843582,\n      \"last-5-avg\": 5834.733065843582,\n      \"last-10-avg\": 5834.733065843582\n    },\n    \"time_since_restore\": {\n      \"max\": 5834.733065843582,\n      \"min\": 5834.733065843582,\n      \"avg\": 5834.733065843582,\n      \"last\": 5834.733065843582,\n      \"last-5-avg\": 5834.733065843582,\n      \"last-10-avg\": 5834.733065843582\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824ff182b1e95eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430824ff182b1e95eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6cabbaa340000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6cabbaa340000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6cabbaa340000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6cabbaa340000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6cabbaa340000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6cabbaa340000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00057\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035375f35375f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"57_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00057_57_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717205583.8187444,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8347902097902098,\n    \"timestamp\": 1717216745,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00057\",\n    \"date\": \"2024-06-01_06-39-05\",\n    \"time_this_iter_s\": 5374.839807987213,\n    \"time_total_s\": 11161.802406549454,\n    \"pid\": 505979,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11161.802406549454,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"57_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717216745.6290607,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8347902097902098,\n      \"min\": 0.7463474025974026,\n      \"avg\": 0.7905688061938062,\n      \"last\": 0.8347902097902098,\n      \"last-5-avg\": 0.7905688061938062,\n      \"last-10-avg\": 0.7905688061938062\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5786.962598562241,\n      \"min\": 5374.839807987213,\n      \"avg\": 5580.901203274727,\n      \"last\": 5374.839807987213,\n      \"last-5-avg\": 5580.901203274727,\n      \"last-10-avg\": 5580.901203274727\n    },\n    \"time_total_s\": {\n      \"max\": 11161.802406549454,\n      \"min\": 5786.962598562241,\n      \"avg\": 8474.382502555847,\n      \"last\": 11161.802406549454,\n      \"last-5-avg\": 8474.382502555847,\n      \"last-10-avg\": 8474.382502555847\n    },\n    \"time_since_restore\": {\n      \"max\": 11161.802406549454,\n      \"min\": 5786.962598562241,\n      \"avg\": 8474.382502555847,\n      \"last\": 11161.802406549454,\n      \"last-5-avg\": 8474.382502555847,\n      \"last-10-avg\": 8474.382502555847\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085088b3f213e2e73f94869452946807680d4308de3c42f599b6ea3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085088b3f213e2e73f94869452946807680d4308de3c42f599b6ea3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b69af66cdc00004740b4fed6fda80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b69af66cdc00004740b4fed6fda80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b69af66cdc00004740c5cce6b5420000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b69af66cdc00004740c5cce6b5420000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b69af66cdc00004740c5cce6b5420000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b69af66cdc00004740c5cce6b5420000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00091\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039315f39315f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"91_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00091_91_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717623270.8975854,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7804314329738059,\n    \"timestamp\": 1717644552,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00091\",\n    \"date\": \"2024-06-06_05-29-12\",\n    \"time_this_iter_s\": 12681.5901658535,\n    \"time_total_s\": 21281.71273469925,\n    \"pid\": 663219,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 21281.71273469925,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"91_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717644552.6141322,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7804314329738059,\n      \"min\": 0.7102272727272727,\n      \"avg\": 0.7453293528505394,\n      \"last\": 0.7804314329738059,\n      \"last-5-avg\": 0.7453293528505394,\n      \"last-10-avg\": 0.7453293528505394\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12681.5901658535,\n      \"min\": 8600.122568845749,\n      \"avg\": 10640.856367349625,\n      \"last\": 12681.5901658535,\n      \"last-5-avg\": 10640.856367349625,\n      \"last-10-avg\": 10640.856367349625\n    },\n    \"time_total_s\": {\n      \"max\": 21281.71273469925,\n      \"min\": 8600.122568845749,\n      \"avg\": 14940.917651772499,\n      \"last\": 21281.71273469925,\n      \"last-5-avg\": 14940.917651772499,\n      \"last-10-avg\": 14940.917651772499\n    },\n    \"time_since_restore\": {\n      \"max\": 21281.71273469925,\n      \"min\": 8600.122568845749,\n      \"avg\": 14940.917651772499,\n      \"last\": 21281.71273469925,\n      \"last-5-avg\": 14940.917651772499,\n      \"last-10-avg\": 14940.917651772499\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2ebae63f94869452946807680d4308bd922c574bf9e83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2ebae63f94869452946807680d4308bd922c574bf9e83f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c0cc0fb05600004740c8c4cb8a8e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c0cc0fb05600004740c8c4cb8a8e0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c0cc0fb05600004740d4c86d9d720000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c0cc0fb05600004740d4c86d9d720000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c0cc0fb05600004740d4c86d9d720000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c0cc0fb05600004740d4c86d9d720000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00019\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031395f31395f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"19_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00019_19_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716699271.140499,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.916866028708134,\n    \"timestamp\": 1716718007,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00019\",\n    \"date\": \"2024-05-26_12-06-47\",\n    \"time_this_iter_s\": 4086.194212436676,\n    \"time_total_s\": 18736.170177459717,\n    \"pid\": 302403,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 18736.170177459717,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"19_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716718007.3144202,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.916866028708134,\n      \"min\": 0.7989639037433155,\n      \"avg\": 0.8579149662257248,\n      \"last\": 0.916866028708134,\n      \"last-5-avg\": 0.8579149662257248,\n      \"last-10-avg\": 0.8579149662257248\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 14649.97596502304,\n      \"min\": 4086.194212436676,\n      \"avg\": 9368.085088729858,\n      \"last\": 4086.194212436676,\n      \"last-5-avg\": 9368.085088729858,\n      \"last-10-avg\": 9368.085088729858\n    },\n    \"time_total_s\": {\n      \"max\": 18736.170177459717,\n      \"min\": 14649.97596502304,\n      \"avg\": 16693.07307124138,\n      \"last\": 18736.170177459717,\n      \"last-5-avg\": 16693.07307124138,\n      \"last-10-avg\": 16693.07307124138\n    },\n    \"time_since_restore\": {\n      \"max\": 18736.170177459717,\n      \"min\": 14649.97596502304,\n      \"avg\": 16693.07307124138,\n      \"last\": 18736.170177459717,\n      \"last-5-avg\": 16693.07307124138,\n      \"last-10-avg\": 16693.07307124138\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089162a8bf1c91e93f94869452946807680d4308b6ac036df756ed3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089162a8bf1c91e93f94869452946807680d4308b6ac036df756ed3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740cc9cfcec6c00004740afec636fd00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740cc9cfcec6c00004740afec636fd00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740cc9cfcec6c00004740d24c0ae4300000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740cc9cfcec6c00004740d24c0ae4300000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740cc9cfcec6c00004740d24c0ae4300000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740cc9cfcec6c00004740d24c0ae4300000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00065\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036355f36355f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"65_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00065_65_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717306685.3319094,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9084476843910808,\n    \"timestamp\": 1717317541,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00065\",\n    \"date\": \"2024-06-02_10-39-01\",\n    \"time_this_iter_s\": 10855.86621928215,\n    \"time_total_s\": 10855.86621928215,\n    \"pid\": 543828,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10855.86621928215,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"65_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717317541.2000587,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9084476843910808,\n      \"min\": 0.9084476843910808,\n      \"avg\": 0.9084476843910808,\n      \"last\": 0.9084476843910808,\n      \"last-5-avg\": 0.9084476843910808,\n      \"last-10-avg\": 0.9084476843910808\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10855.86621928215,\n      \"min\": 10855.86621928215,\n      \"avg\": 10855.86621928215,\n      \"last\": 10855.86621928215,\n      \"last-5-avg\": 10855.86621928215,\n      \"last-10-avg\": 10855.86621928215\n    },\n    \"time_total_s\": {\n      \"max\": 10855.86621928215,\n      \"min\": 10855.86621928215,\n      \"avg\": 10855.86621928215,\n      \"last\": 10855.86621928215,\n      \"last-5-avg\": 10855.86621928215,\n      \"last-10-avg\": 10855.86621928215\n    },\n    \"time_since_restore\": {\n      \"max\": 10855.86621928215,\n      \"min\": 10855.86621928215,\n      \"avg\": 10855.86621928215,\n      \"last\": 10855.86621928215,\n      \"last-5-avg\": 10855.86621928215,\n      \"last-10-avg\": 10855.86621928215\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089bc5d2e00012ed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089bc5d2e00012ed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c533eee0460000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c533eee0460000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c533eee0460000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c533eee0460000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c533eee0460000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c533eee0460000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00060\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036305f36305f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"60_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00060_60_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717235270.3418605,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.6399147727272727,\n    \"timestamp\": 1717243707,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00060\",\n    \"date\": \"2024-06-01_14-08-27\",\n    \"time_this_iter_s\": 3295.982408761978,\n    \"time_total_s\": 8436.868916034698,\n    \"pid\": 517257,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8436.868916034698,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"60_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717243707.215078,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6399147727272727,\n      \"min\": 0.6268181818181818,\n      \"avg\": 0.6333664772727272,\n      \"last\": 0.6399147727272727,\n      \"last-5-avg\": 0.6333664772727272,\n      \"last-10-avg\": 0.6333664772727272\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5140.88650727272,\n      \"min\": 3295.982408761978,\n      \"avg\": 4218.434458017349,\n      \"last\": 3295.982408761978,\n      \"last-5-avg\": 4218.434458017349,\n      \"last-10-avg\": 4218.434458017349\n    },\n    \"time_total_s\": {\n      \"max\": 8436.868916034698,\n      \"min\": 5140.88650727272,\n      \"avg\": 6788.877711653709,\n      \"last\": 8436.868916034698,\n      \"last-5-avg\": 6788.877711653709,\n      \"last-10-avg\": 6788.877711653709\n    },\n    \"time_since_restore\": {\n      \"max\": 8436.868916034698,\n      \"min\": 5140.88650727272,\n      \"avg\": 6788.877711653709,\n      \"last\": 8436.868916034698,\n      \"last-5-avg\": 6788.877711653709,\n      \"last-10-avg\": 6788.877711653709\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080f50ee00e50ee43f94869452946807680d4308bae8a28b2e7ae43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080f50ee00e50ee43f94869452946807680d4308bae8a28b2e7ae43f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b414e2f22400004740a9bff6fe480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b414e2f22400004740a9bff6fe480000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b414e2f22400004740c07a6f38a40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b414e2f22400004740c07a6f38a40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b414e2f22400004740c07a6f38a40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b414e2f22400004740c07a6f38a40000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00003\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030335f335f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"3_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00003_3_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716513176.9287128,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8985200845665962,\n    \"timestamp\": 1716522650,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00003\",\n    \"date\": \"2024-05-24_05-50-50\",\n    \"time_this_iter_s\": 9473.82126379013,\n    \"time_total_s\": 9473.82126379013,\n    \"pid\": 219627,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9473.82126379013,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"3_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716522650.751794,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8985200845665962,\n      \"min\": 0.8985200845665962,\n      \"avg\": 0.8985200845665962,\n      \"last\": 0.8985200845665962,\n      \"last-5-avg\": 0.8985200845665962,\n      \"last-10-avg\": 0.8985200845665962\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 9473.82126379013,\n      \"min\": 9473.82126379013,\n      \"avg\": 9473.82126379013,\n      \"last\": 9473.82126379013,\n      \"last-5-avg\": 9473.82126379013,\n      \"last-10-avg\": 9473.82126379013\n    },\n    \"time_total_s\": {\n      \"max\": 9473.82126379013,\n      \"min\": 9473.82126379013,\n      \"avg\": 9473.82126379013,\n      \"last\": 9473.82126379013,\n      \"last-5-avg\": 9473.82126379013,\n      \"last-10-avg\": 9473.82126379013\n    },\n    \"time_since_restore\": {\n      \"max\": 9473.82126379013,\n      \"min\": 9473.82126379013,\n      \"avg\": 9473.82126379013,\n      \"last\": 9473.82126379013,\n      \"last-5-avg\": 9473.82126379013,\n      \"last-10-avg\": 9473.82126379013\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea674031adc0ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea674031adc0ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c280e91f2c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c280e91f2c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c280e91f2c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c280e91f2c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c280e91f2c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c280e91f2c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00010\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031305f31305f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"10_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00010_10_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716594411.6850085,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8644886363636364,\n    \"timestamp\": 1716603050,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00010\",\n    \"date\": \"2024-05-25_04-10-50\",\n    \"time_this_iter_s\": 8638.671243190765,\n    \"time_total_s\": 8638.671243190765,\n    \"pid\": 262860,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8638.671243190765,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"10_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716603050.3582873,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8644886363636364,\n      \"min\": 0.8644886363636364,\n      \"avg\": 0.8644886363636364,\n      \"last\": 0.8644886363636364,\n      \"last-5-avg\": 0.8644886363636364,\n      \"last-10-avg\": 0.8644886363636364\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8638.671243190765,\n      \"min\": 8638.671243190765,\n      \"avg\": 8638.671243190765,\n      \"last\": 8638.671243190765,\n      \"last-5-avg\": 8638.671243190765,\n      \"last-10-avg\": 8638.671243190765\n    },\n    \"time_total_s\": {\n      \"max\": 8638.671243190765,\n      \"min\": 8638.671243190765,\n      \"avg\": 8638.671243190765,\n      \"last\": 8638.671243190765,\n      \"last-5-avg\": 8638.671243190765,\n      \"last-10-avg\": 8638.671243190765\n    },\n    \"time_since_restore\": {\n      \"max\": 8638.671243190765,\n      \"min\": 8638.671243190765,\n      \"avg\": 8638.671243190765,\n      \"last\": 8638.671243190765,\n      \"last-5-avg\": 8638.671243190765,\n      \"last-10-avg\": 8638.671243190765\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a419e12e4a9eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a419e12e4a9eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0df55eb4c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0df55eb4c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0df55eb4c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0df55eb4c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0df55eb4c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0df55eb4c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00093\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039335f39335f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"93_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00093_93_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717658541.3568888,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7981601731601732,\n    \"timestamp\": 1717668133,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00093\",\n    \"date\": \"2024-06-06_12-02-13\",\n    \"time_this_iter_s\": 4392.454411029816,\n    \"time_total_s\": 9592.610445976257,\n    \"pid\": 676847,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9592.610445976257,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"93_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717668133.9710405,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7981601731601732,\n      \"min\": 0.7177272727272727,\n      \"avg\": 0.7579437229437229,\n      \"last\": 0.7981601731601732,\n      \"last-5-avg\": 0.7579437229437229,\n      \"last-10-avg\": 0.7579437229437229\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5200.156034946442,\n      \"min\": 4392.454411029816,\n      \"avg\": 4796.305222988129,\n      \"last\": 4392.454411029816,\n      \"last-5-avg\": 4796.305222988129,\n      \"last-10-avg\": 4796.305222988129\n    },\n    \"time_total_s\": {\n      \"max\": 9592.610445976257,\n      \"min\": 5200.156034946442,\n      \"avg\": 7396.3832404613495,\n      \"last\": 9592.610445976257,\n      \"last-5-avg\": 7396.3832404613495,\n      \"last-10-avg\": 7396.3832404613495\n    },\n    \"time_since_restore\": {\n      \"max\": 9592.610445976257,\n      \"min\": 5200.156034946442,\n      \"avg\": 7396.3832404613495,\n      \"last\": 9592.610445976257,\n      \"last-5-avg\": 7396.3832404613495,\n      \"last-10-avg\": 7396.3832404613495\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f7f2792f9ff7e63f94869452946807680d43081d2a1634878ae93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f7f2792f9ff7e63f94869452946807680d43081d2a1634878ae93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b45027f1e800004740b1287454480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b45027f1e800004740b1287454480000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b45027f1e800004740c2bc4e23180000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b45027f1e800004740c2bc4e23180000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b45027f1e800004740c2bc4e23180000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b45027f1e800004740c2bc4e23180000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00039\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033395f33395f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"39_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00039_39_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716990129.514711,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8442234848484848,\n    \"timestamp\": 1716995470,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00039\",\n    \"date\": \"2024-05-29_17-11-10\",\n    \"time_this_iter_s\": 5341.11466383934,\n    \"time_total_s\": 5341.11466383934,\n    \"pid\": 414223,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 5341.11466383934,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"39_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716995470.6313767,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8442234848484848,\n      \"min\": 0.8442234848484848,\n      \"avg\": 0.8442234848484848,\n      \"last\": 0.8442234848484848,\n      \"last-5-avg\": 0.8442234848484848,\n      \"last-10-avg\": 0.8442234848484848\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5341.11466383934,\n      \"min\": 5341.11466383934,\n      \"avg\": 5341.11466383934,\n      \"last\": 5341.11466383934,\n      \"last-5-avg\": 5341.11466383934,\n      \"last-10-avg\": 5341.11466383934\n    },\n    \"time_total_s\": {\n      \"max\": 5341.11466383934,\n      \"min\": 5341.11466383934,\n      \"avg\": 5341.11466383934,\n      \"last\": 5341.11466383934,\n      \"last-5-avg\": 5341.11466383934,\n      \"last-10-avg\": 5341.11466383934\n    },\n    \"time_since_restore\": {\n      \"max\": 5341.11466383934,\n      \"min\": 5341.11466383934,\n      \"avg\": 5341.11466383934,\n      \"last\": 5341.11466383934,\n      \"last-5-avg\": 5341.11466383934,\n      \"last-10-avg\": 5341.11466383934\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308830f3ef8e003eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308830f3ef8e003eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b4dd1d5a9c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b4dd1d5a9c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b4dd1d5a9c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b4dd1d5a9c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b4dd1d5a9c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b4dd1d5a9c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00028\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032385f32385f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"28_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00028_28_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716814702.8526285,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7732007575757577,\n    \"timestamp\": 1716824273,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00028\",\n    \"date\": \"2024-05-27_17-37-53\",\n    \"time_this_iter_s\": 5007.536383867264,\n    \"time_total_s\": 9570.53819656372,\n    \"pid\": 346118,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9570.53819656372,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"28_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716824273.3945963,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7732007575757577,\n      \"min\": 0.678202479338843,\n      \"avg\": 0.7257016184573004,\n      \"last\": 0.7732007575757577,\n      \"last-5-avg\": 0.7257016184573004,\n      \"last-10-avg\": 0.7257016184573004\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5007.536383867264,\n      \"min\": 4563.001812696457,\n      \"avg\": 4785.26909828186,\n      \"last\": 5007.536383867264,\n      \"last-5-avg\": 4785.26909828186,\n      \"last-10-avg\": 4785.26909828186\n    },\n    \"time_total_s\": {\n      \"max\": 9570.53819656372,\n      \"min\": 4563.001812696457,\n      \"avg\": 7066.770004630089,\n      \"last\": 9570.53819656372,\n      \"last-5-avg\": 7066.770004630089,\n      \"last-10-avg\": 7066.770004630089\n    },\n    \"time_since_restore\": {\n      \"max\": 9570.53819656372,\n      \"min\": 4563.001812696457,\n      \"avg\": 7066.770004630089,\n      \"last\": 9570.53819656372,\n      \"last-5-avg\": 7066.770004630089,\n      \"last-10-avg\": 7066.770004630089\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430840729aafd5b3e53f94869452946807680d43083ff8e0830fbee83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430840729aafd5b3e53f94869452946807680d43083ff8e0830fbee83f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b1d30076cc00004740b38f8950740000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b1d30076cc00004740b38f8950740000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b1d30076cc00004740c2b144e3a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b1d30076cc00004740c2b144e3a00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b1d30076cc00004740c2b144e3a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b1d30076cc00004740c2b144e3a00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00075\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037355f37355f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"75_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00075_75_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717438984.662585,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8920454545454545,\n    \"timestamp\": 1717449318,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00075\",\n    \"date\": \"2024-06-03_23-15-18\",\n    \"time_this_iter_s\": 10333.858569860458,\n    \"time_total_s\": 10333.858569860458,\n    \"pid\": 593221,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10333.858569860458,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"75_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717449318.5231256,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8920454545454545,\n      \"min\": 0.8920454545454545,\n      \"avg\": 0.8920454545454545,\n      \"last\": 0.8920454545454545,\n      \"last-5-avg\": 0.8920454545454545,\n      \"last-10-avg\": 0.8920454545454545\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10333.858569860458,\n      \"min\": 10333.858569860458,\n      \"avg\": 10333.858569860458,\n      \"last\": 10333.858569860458,\n      \"last-5-avg\": 10333.858569860458,\n      \"last-10-avg\": 10333.858569860458\n    },\n    \"time_total_s\": {\n      \"max\": 10333.858569860458,\n      \"min\": 10333.858569860458,\n      \"avg\": 10333.858569860458,\n      \"last\": 10333.858569860458,\n      \"last-5-avg\": 10333.858569860458,\n      \"last-10-avg\": 10333.858569860458\n    },\n    \"time_since_restore\": {\n      \"max\": 10333.858569860458,\n      \"min\": 10333.858569860458,\n      \"avg\": 10333.858569860458,\n      \"last\": 10333.858569860458,\n      \"last-5-avg\": 10333.858569860458,\n      \"last-10-avg\": 10333.858569860458\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088b2ebae8a28bec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088b2ebae8a28bec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c42eede59e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c42eede59e0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c42eede59e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c42eede59e0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c42eede59e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c42eede59e0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00043\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034335f34335f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"43_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00043_43_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717023499.6927133,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8988636363636363,\n    \"timestamp\": 1717041320,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00043\",\n    \"date\": \"2024-05-30_05-55-20\",\n    \"time_this_iter_s\": 17821.246937036514,\n    \"time_total_s\": 17821.246937036514,\n    \"pid\": 426780,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 17821.246937036514,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"43_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717041320.9418695,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8988636363636363,\n      \"min\": 0.8988636363636363,\n      \"avg\": 0.8988636363636363,\n      \"last\": 0.8988636363636363,\n      \"last-5-avg\": 0.8988636363636363,\n      \"last-10-avg\": 0.8988636363636363\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 17821.246937036514,\n      \"min\": 17821.246937036514,\n      \"avg\": 17821.246937036514,\n      \"last\": 17821.246937036514,\n      \"last-5-avg\": 17821.246937036514,\n      \"last-10-avg\": 17821.246937036514\n    },\n    \"time_total_s\": {\n      \"max\": 17821.246937036514,\n      \"min\": 17821.246937036514,\n      \"avg\": 17821.246937036514,\n      \"last\": 17821.246937036514,\n      \"last-5-avg\": 17821.246937036514,\n      \"last-10-avg\": 17821.246937036514\n    },\n    \"time_since_restore\": {\n      \"max\": 17821.246937036514,\n      \"min\": 17821.246937036514,\n      \"avg\": 17821.246937036514,\n      \"last\": 17821.246937036514,\n      \"last-5-avg\": 17821.246937036514,\n      \"last-10-avg\": 17821.246937036514\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3da37ac7dc3ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c3da37ac7dc3ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1674fcdd10000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1674fcdd10000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1674fcdd10000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1674fcdd10000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1674fcdd10000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1674fcdd10000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00055\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035355f35355f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"55_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00055_55_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717183221.3176792,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8362299465240642,\n    \"timestamp\": 1717194233,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00055\",\n    \"date\": \"2024-06-01_00-23-53\",\n    \"time_this_iter_s\": 11012.325834035873,\n    \"time_total_s\": 11012.325834035873,\n    \"pid\": 497223,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11012.325834035873,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"55_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717194233.6469288,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8362299465240642,\n      \"min\": 0.8362299465240642,\n      \"avg\": 0.8362299465240642,\n      \"last\": 0.8362299465240642,\n      \"last-5-avg\": 0.8362299465240642,\n      \"last-10-avg\": 0.8362299465240642\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11012.325834035873,\n      \"min\": 11012.325834035873,\n      \"avg\": 11012.325834035873,\n      \"last\": 11012.325834035873,\n      \"last-5-avg\": 11012.325834035873,\n      \"last-10-avg\": 11012.325834035873\n    },\n    \"time_total_s\": {\n      \"max\": 11012.325834035873,\n      \"min\": 11012.325834035873,\n      \"avg\": 11012.325834035873,\n      \"last\": 11012.325834035873,\n      \"last-5-avg\": 11012.325834035873,\n      \"last-10-avg\": 11012.325834035873\n    },\n    \"time_since_restore\": {\n      \"max\": 11012.325834035873,\n      \"min\": 11012.325834035873,\n      \"avg\": 11012.325834035873,\n      \"last\": 11012.325834035873,\n      \"last-5-avg\": 11012.325834035873,\n      \"last-10-avg\": 11012.325834035873\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c336084e65c2ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c336084e65c2ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c58229b4ee0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c58229b4ee0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c58229b4ee0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c58229b4ee0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c58229b4ee0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c58229b4ee0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00049\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034395f34395f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"49_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00049_49_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717109435.0075479,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8484848484848484,\n    \"timestamp\": 1717122997,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00049\",\n    \"date\": \"2024-05-31_04-36-37\",\n    \"time_this_iter_s\": 6160.313851356506,\n    \"time_total_s\": 13562.237166166306,\n    \"pid\": 469047,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13562.237166166306,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"49_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717122997.2489867,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8484848484848484,\n      \"min\": 0.7771464646464648,\n      \"avg\": 0.8128156565656566,\n      \"last\": 0.8484848484848484,\n      \"last-5-avg\": 0.8128156565656566,\n      \"last-10-avg\": 0.8128156565656566\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7401.923314809799,\n      \"min\": 6160.313851356506,\n      \"avg\": 6781.118583083153,\n      \"last\": 6160.313851356506,\n      \"last-5-avg\": 6781.118583083153,\n      \"last-10-avg\": 6781.118583083153\n    },\n    \"time_total_s\": {\n      \"max\": 13562.237166166306,\n      \"min\": 7401.923314809799,\n      \"avg\": 10482.080240488052,\n      \"last\": 13562.237166166306,\n      \"last-5-avg\": 10482.080240488052,\n      \"last-10-avg\": 10482.080240488052\n    },\n    \"time_since_restore\": {\n      \"max\": 13562.237166166306,\n      \"min\": 7401.923314809799,\n      \"avg\": 10482.080240488052,\n      \"last\": 13562.237166166306,\n      \"last-5-avg\": 10482.080240488052,\n      \"last-10-avg\": 10482.080240488052\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088a793b4362dee83f94869452946807680d4308269b6cb2c926eb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088a793b4362dee83f94869452946807680d4308269b6cb2c926eb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bce9ec5e5c00004740b8105058900000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bce9ec5e5c00004740b8105058900000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bce9ec5e5c00004740ca7d1e5b760000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bce9ec5e5c00004740ca7d1e5b760000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bce9ec5e5c00004740ca7d1e5b760000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bce9ec5e5c00004740ca7d1e5b760000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00023\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032335f32335f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e31305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"23_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00023_23_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.10_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716763478.2701025,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8168290043290044,\n    \"timestamp\": 1716772527,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00023\",\n    \"date\": \"2024-05-27_03-15-27\",\n    \"time_this_iter_s\": 9048.863273620605,\n    \"time_total_s\": 9048.863273620605,\n    \"pid\": 327084,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9048.863273620605,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"23_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716772527.1353593,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8168290043290044,\n      \"min\": 0.8168290043290044,\n      \"avg\": 0.8168290043290044,\n      \"last\": 0.8168290043290044,\n      \"last-5-avg\": 0.8168290043290044,\n      \"last-10-avg\": 0.8168290043290044\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 9048.863273620605,\n      \"min\": 9048.863273620605,\n      \"avg\": 9048.863273620605,\n      \"last\": 9048.863273620605,\n      \"last-5-avg\": 9048.863273620605,\n      \"last-10-avg\": 9048.863273620605\n    },\n    \"time_total_s\": {\n      \"max\": 9048.863273620605,\n      \"min\": 9048.863273620605,\n      \"avg\": 9048.863273620605,\n      \"last\": 9048.863273620605,\n      \"last-5-avg\": 9048.863273620605,\n      \"last-10-avg\": 9048.863273620605\n    },\n    \"time_since_restore\": {\n      \"max\": 9048.863273620605,\n      \"min\": 9048.863273620605,\n      \"avg\": 9048.863273620605,\n      \"last\": 9048.863273620605,\n      \"last-5-avg\": 9048.863273620605,\n      \"last-10-avg\": 9048.863273620605\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308db8d80947623ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308db8d80947623ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c1ac6e7fc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c1ac6e7fc00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c1ac6e7fc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c1ac6e7fc00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c1ac6e7fc00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c1ac6e7fc00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00008\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059535030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c956f626a6563746976655f35623364665f30303030385f385f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"8_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00008_8_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716571106.4451005,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8784722222222222,\n    \"timestamp\": 1716578528,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00008\",\n    \"date\": \"2024-05-24_21-22-08\",\n    \"time_this_iter_s\": 7421.686295032501,\n    \"time_total_s\": 7421.686295032501,\n    \"pid\": 254368,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 7421.686295032501,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"8_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716578528.1331992,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8784722222222222,\n      \"min\": 0.8784722222222222,\n      \"avg\": 0.8784722222222222,\n      \"last\": 0.8784722222222222,\n      \"last-5-avg\": 0.8784722222222222,\n      \"last-10-avg\": 0.8784722222222222\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7421.686295032501,\n      \"min\": 7421.686295032501,\n      \"avg\": 7421.686295032501,\n      \"last\": 7421.686295032501,\n      \"last-5-avg\": 7421.686295032501,\n      \"last-10-avg\": 7421.686295032501\n    },\n    \"time_total_s\": {\n      \"max\": 7421.686295032501,\n      \"min\": 7421.686295032501,\n      \"avg\": 7421.686295032501,\n      \"last\": 7421.686295032501,\n      \"last-5-avg\": 7421.686295032501,\n      \"last-10-avg\": 7421.686295032501\n    },\n    \"time_since_restore\": {\n      \"max\": 7421.686295032501,\n      \"min\": 7421.686295032501,\n      \"avg\": 7421.686295032501,\n      \"last\": 7421.686295032501,\n      \"last-5-avg\": 7421.686295032501,\n      \"last-10-avg\": 7421.686295032501\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c7711cc7711cec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c7711cc7711cec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bcfdafb1080000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bcfdafb1080000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bcfdafb1080000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bcfdafb1080000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bcfdafb1080000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bcfdafb1080000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00089\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038395f38395f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"89_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00089_89_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717597775.974943,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.803698752228164,\n    \"timestamp\": 1717614010,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00089\",\n    \"date\": \"2024-06-05_21-00-10\",\n    \"time_this_iter_s\": 10477.085927248001,\n    \"time_total_s\": 16234.35212302208,\n    \"pid\": 654029,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16234.35212302208,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"89_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717614010.3310533,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.803698752228164,\n      \"min\": 0.7560876623376622,\n      \"avg\": 0.7798932072829131,\n      \"last\": 0.803698752228164,\n      \"last-5-avg\": 0.7798932072829131,\n      \"last-10-avg\": 0.7798932072829131\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10477.085927248001,\n      \"min\": 5757.266195774078,\n      \"avg\": 8117.17606151104,\n      \"last\": 10477.085927248001,\n      \"last-5-avg\": 8117.17606151104,\n      \"last-10-avg\": 8117.17606151104\n    },\n    \"time_total_s\": {\n      \"max\": 16234.35212302208,\n      \"min\": 5757.266195774078,\n      \"avg\": 10995.809159398079,\n      \"last\": 16234.35212302208,\n      \"last-5-avg\": 10995.809159398079,\n      \"last-10-avg\": 10995.809159398079\n    },\n    \"time_since_restore\": {\n      \"max\": 16234.35212302208,\n      \"min\": 5757.266195774078,\n      \"avg\": 10995.809159398079,\n      \"last\": 16234.35212302208,\n      \"last-5-avg\": 10995.809159398079,\n      \"last-10-avg\": 10995.809159398079\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087ac7d4c0de31e83f94869452946807680d4308b8fd1472e6b7e93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087ac7d4c0de31e83f94869452946807680d4308b8fd1472e6b7e93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b67d44256800004740c4768affaa0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b67d44256800004740c4768affaa0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b67d44256800004740cfb52d125e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b67d44256800004740cfb52d125e0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b67d44256800004740cfb52d125e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b67d44256800004740cfb52d125e0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00047\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034375f34375f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"47_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00047_47_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717074436.6068938,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8845620842572062,\n    \"timestamp\": 1717092229,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00047\",\n    \"date\": \"2024-05-30_20-03-49\",\n    \"time_this_iter_s\": 17793.07422733307,\n    \"time_total_s\": 17793.07422733307,\n    \"pid\": 456132,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 17793.07422733307,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"47_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717092229.6831856,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8845620842572062,\n      \"min\": 0.8845620842572062,\n      \"avg\": 0.8845620842572062,\n      \"last\": 0.8845620842572062,\n      \"last-5-avg\": 0.8845620842572062,\n      \"last-10-avg\": 0.8845620842572062\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 17793.07422733307,\n      \"min\": 17793.07422733307,\n      \"avg\": 17793.07422733307,\n      \"last\": 17793.07422733307,\n      \"last-5-avg\": 17793.07422733307,\n      \"last-10-avg\": 17793.07422733307\n    },\n    \"time_total_s\": {\n      \"max\": 17793.07422733307,\n      \"min\": 17793.07422733307,\n      \"avg\": 17793.07422733307,\n      \"last\": 17793.07422733307,\n      \"last-5-avg\": 17793.07422733307,\n      \"last-10-avg\": 17793.07422733307\n    },\n    \"time_since_restore\": {\n      \"max\": 17793.07422733307,\n      \"min\": 17793.07422733307,\n      \"avg\": 17793.07422733307,\n      \"last\": 17793.07422733307,\n      \"last-5-avg\": 17793.07422733307,\n      \"last-10-avg\": 17793.07422733307\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084e52e524554eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084e52e524554eec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d16044c0240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d16044c0240000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d16044c0240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d16044c0240000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d16044c0240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d16044c0240000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00068\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036385f36385f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"68_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00068_68_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717359325.4136493,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8822798295454545,\n    \"timestamp\": 1717372492,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00068\",\n    \"date\": \"2024-06-03_01-54-52\",\n    \"time_this_iter_s\": 13166.655459880829,\n    \"time_total_s\": 13166.655459880829,\n    \"pid\": 563113,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13166.655459880829,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"68_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717372492.0710027,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8822798295454545,\n      \"min\": 0.8822798295454545,\n      \"avg\": 0.8822798295454545,\n      \"last\": 0.8822798295454545,\n      \"last-5-avg\": 0.8822798295454545,\n      \"last-10-avg\": 0.8822798295454545\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 13166.655459880829,\n      \"min\": 13166.655459880829,\n      \"avg\": 13166.655459880829,\n      \"last\": 13166.655459880829,\n      \"last-5-avg\": 13166.655459880829,\n      \"last-10-avg\": 13166.655459880829\n    },\n    \"time_total_s\": {\n      \"max\": 13166.655459880829,\n      \"min\": 13166.655459880829,\n      \"avg\": 13166.655459880829,\n      \"last\": 13166.655459880829,\n      \"last-5-avg\": 13166.655459880829,\n      \"last-10-avg\": 13166.655459880829\n    },\n    \"time_since_restore\": {\n      \"max\": 13166.655459880829,\n      \"min\": 13166.655459880829,\n      \"avg\": 13166.655459880829,\n      \"last\": 13166.655459880829,\n      \"last-5-avg\": 13166.655459880829,\n      \"last-10-avg\": 13166.655459880829\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088b2ebae8a23bec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088b2ebae8a23bec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c9b753e61c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c9b753e61c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c9b753e61c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c9b753e61c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c9b753e61c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c9b753e61c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00062\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036325f36325f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"62_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00062_62_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717255365.413455,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7987440191387559,\n    \"timestamp\": 1717269262,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00062\",\n    \"date\": \"2024-06-01_21-14-22\",\n    \"time_this_iter_s\": 8245.530615329742,\n    \"time_total_s\": 13897.381160497665,\n    \"pid\": 524473,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13897.381160497665,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"62_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717269262.7989008,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7987440191387559,\n      \"min\": 0.7145979020979021,\n      \"avg\": 0.7566709606183291,\n      \"last\": 0.7987440191387559,\n      \"last-5-avg\": 0.7566709606183291,\n      \"last-10-avg\": 0.7566709606183291\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8245.530615329742,\n      \"min\": 5651.850545167923,\n      \"avg\": 6948.690580248833,\n      \"last\": 8245.530615329742,\n      \"last-5-avg\": 6948.690580248833,\n      \"last-10-avg\": 6948.690580248833\n    },\n    \"time_total_s\": {\n      \"max\": 13897.381160497665,\n      \"min\": 5651.850545167923,\n      \"avg\": 9774.615852832794,\n      \"last\": 13897.381160497665,\n      \"last-5-avg\": 9774.615852832794,\n      \"last-10-avg\": 9774.615852832794\n    },\n    \"time_since_restore\": {\n      \"max\": 13897.381160497665,\n      \"min\": 5651.850545167923,\n      \"avg\": 9774.615852832794,\n      \"last\": 13897.381160497665,\n      \"last-5-avg\": 9774.615852832794,\n      \"last-10-avg\": 9774.615852832794\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308549f696bfcdde63f94869452946807680d43082373029e4f8fe93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308549f696bfcdde63f94869452946807680d43082373029e4f8fe93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b613d9bd5400004740c01ac3eb340000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b613d9bd5400004740c01ac3eb340000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b613d9bd5400004740cb24b0c9de0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b613d9bd5400004740cb24b0c9de0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b613d9bd5400004740cb24b0c9de0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b613d9bd5400004740cb24b0c9de0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00052\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035325f35325f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"52_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00052_52_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717151198.3993025,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8399122807017544,\n    \"timestamp\": 1717162931,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00052\",\n    \"date\": \"2024-05-31_15-42-11\",\n    \"time_this_iter_s\": 11733.422400712967,\n    \"time_total_s\": 11733.422400712967,\n    \"pid\": 484721,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11733.422400712967,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"52_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717162931.8242383,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8399122807017544,\n      \"min\": 0.8399122807017544,\n      \"avg\": 0.8399122807017544,\n      \"last\": 0.8399122807017544,\n      \"last-5-avg\": 0.8399122807017544,\n      \"last-10-avg\": 0.8399122807017544\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11733.422400712967,\n      \"min\": 11733.422400712967,\n      \"avg\": 11733.422400712967,\n      \"last\": 11733.422400712967,\n      \"last-5-avg\": 11733.422400712967,\n      \"last-10-avg\": 11733.422400712967\n    },\n    \"time_total_s\": {\n      \"max\": 11733.422400712967,\n      \"min\": 11733.422400712967,\n      \"avg\": 11733.422400712967,\n      \"last\": 11733.422400712967,\n      \"last-5-avg\": 11733.422400712967,\n      \"last-10-avg\": 11733.422400712967\n    },\n    \"time_since_restore\": {\n      \"max\": 11733.422400712967,\n      \"min\": 11733.422400712967,\n      \"avg\": 11733.422400712967,\n      \"last\": 11733.422400712967,\n      \"last-5-avg\": 11733.422400712967,\n      \"last-10-avg\": 11733.422400712967\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430809ee23b88fe0ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430809ee23b88fe0ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c6eab6113a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c6eab6113a0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c6eab6113a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c6eab6113a0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c6eab6113a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c6eab6113a0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00044\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034345f34345f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"44_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00044_44_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717041323.4897199,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8011363636363636,\n    \"timestamp\": 1717055444,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00044\",\n    \"date\": \"2024-05-30_09-50-44\",\n    \"time_this_iter_s\": 3421.2830941677094,\n    \"time_total_s\": 14121.076851129532,\n    \"pid\": 433617,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 14121.076851129532,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"44_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717055444.5713089,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8011363636363636,\n      \"min\": 0.7170454545454547,\n      \"avg\": 0.7590909090909091,\n      \"last\": 0.8011363636363636,\n      \"last-5-avg\": 0.7590909090909091,\n      \"last-10-avg\": 0.7590909090909091\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10699.793756961823,\n      \"min\": 3421.2830941677094,\n      \"avg\": 7060.538425564766,\n      \"last\": 3421.2830941677094,\n      \"last-5-avg\": 7060.538425564766,\n      \"last-10-avg\": 7060.538425564766\n    },\n    \"time_total_s\": {\n      \"max\": 14121.076851129532,\n      \"min\": 10699.793756961823,\n      \"avg\": 12410.435304045677,\n      \"last\": 14121.076851129532,\n      \"last-5-avg\": 12410.435304045677,\n      \"last-10-avg\": 12410.435304045677\n    },\n    \"time_since_restore\": {\n      \"max\": 14121.076851129532,\n      \"min\": 10699.793756961823,\n      \"avg\": 12410.435304045677,\n      \"last\": 14121.076851129532,\n      \"last-5-avg\": 12410.435304045677,\n      \"last-10-avg\": 12410.435304045677\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f394204f09f2e63f94869452946807680d4308a38b2ebae8a2e93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f394204f09f2e63f94869452946807680d4308a38b2ebae8a2e93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4e5e599d400004740aaba90f1b80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c4e5e599d400004740aaba90f1b80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4e5e599d400004740cb9489d6420000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c4e5e599d400004740cb9489d6420000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c4e5e599d400004740cb9489d6420000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c4e5e599d400004740cb9489d6420000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00070\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037305f37305f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"70_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00070_70_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717376632.112451,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.905923994038748,\n    \"timestamp\": 1717402982,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00070\",\n    \"date\": \"2024-06-03_10-23-02\",\n    \"time_this_iter_s\": 26350.268820524216,\n    \"time_total_s\": 26350.268820524216,\n    \"pid\": 569403,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 26350.268820524216,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"70_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717402982.3831708,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.905923994038748,\n      \"min\": 0.905923994038748,\n      \"avg\": 0.905923994038748,\n      \"last\": 0.905923994038748,\n      \"last-5-avg\": 0.905923994038748,\n      \"last-10-avg\": 0.905923994038748\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 26350.268820524216,\n      \"min\": 26350.268820524216,\n      \"avg\": 26350.268820524216,\n      \"last\": 26350.268820524216,\n      \"last-5-avg\": 26350.268820524216,\n      \"last-10-avg\": 26350.268820524216\n    },\n    \"time_total_s\": {\n      \"max\": 26350.268820524216,\n      \"min\": 26350.268820524216,\n      \"avg\": 26350.268820524216,\n      \"last\": 26350.268820524216,\n      \"last-5-avg\": 26350.268820524216,\n      \"last-10-avg\": 26350.268820524216\n    },\n    \"time_since_restore\": {\n      \"max\": 26350.268820524216,\n      \"min\": 26350.268820524216,\n      \"avg\": 26350.268820524216,\n      \"last\": 26350.268820524216,\n      \"last-5-avg\": 26350.268820524216,\n      \"last-10-avg\": 26350.268820524216\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430822dce15054fdec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430822dce15054fdec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d9bb91345b0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d9bb91345b0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d9bb91345b0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d9bb91345b0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d9bb91345b0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d9bb91345b0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00074\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037345f37345f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"74_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00074_74_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717430309.3855784,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.865625,\n    \"timestamp\": 1717438982,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00074\",\n    \"date\": \"2024-06-03_20-23-02\",\n    \"time_this_iter_s\": 8672.944174051285,\n    \"time_total_s\": 8672.944174051285,\n    \"pid\": 590182,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8672.944174051285,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"74_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717438982.3317006,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.865625,\n      \"min\": 0.865625,\n      \"avg\": 0.865625,\n      \"last\": 0.865625,\n      \"last-5-avg\": 0.865625,\n      \"last-10-avg\": 0.865625\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8672.944174051285,\n      \"min\": 8672.944174051285,\n      \"avg\": 8672.944174051285,\n      \"last\": 8672.944174051285,\n      \"last-5-avg\": 8672.944174051285,\n      \"last-10-avg\": 8672.944174051285\n    },\n    \"time_total_s\": {\n      \"max\": 8672.944174051285,\n      \"min\": 8672.944174051285,\n      \"avg\": 8672.944174051285,\n      \"last\": 8672.944174051285,\n      \"last-5-avg\": 8672.944174051285,\n      \"last-10-avg\": 8672.944174051285\n    },\n    \"time_since_restore\": {\n      \"max\": 8672.944174051285,\n      \"min\": 8672.944174051285,\n      \"avg\": 8672.944174051285,\n      \"last\": 8672.944174051285,\n      \"last-5-avg\": 8672.944174051285,\n      \"last-10-avg\": 8672.944174051285\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333333b3eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333333b3eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0f078dab20000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0f078dab20000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0f078dab20000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0f078dab20000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0f078dab20000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0f078dab20000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00038\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033385f33385f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"38_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00038_38_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716971715.59578,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8918449197860964,\n    \"timestamp\": 1716990127,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00038\",\n    \"date\": \"2024-05-29_15-42-07\",\n    \"time_this_iter_s\": 18411.469071626663,\n    \"time_total_s\": 18411.469071626663,\n    \"pid\": 406879,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 18411.469071626663,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"38_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716990127.0668454,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8918449197860964,\n      \"min\": 0.8918449197860964,\n      \"avg\": 0.8918449197860964,\n      \"last\": 0.8918449197860964,\n      \"last-5-avg\": 0.8918449197860964,\n      \"last-10-avg\": 0.8918449197860964\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 18411.469071626663,\n      \"min\": 18411.469071626663,\n      \"avg\": 18411.469071626663,\n      \"last\": 18411.469071626663,\n      \"last-5-avg\": 18411.469071626663,\n      \"last-10-avg\": 18411.469071626663\n    },\n    \"time_total_s\": {\n      \"max\": 18411.469071626663,\n      \"min\": 18411.469071626663,\n      \"avg\": 18411.469071626663,\n      \"last\": 18411.469071626663,\n      \"last-5-avg\": 18411.469071626663,\n      \"last-10-avg\": 18411.469071626663\n    },\n    \"time_since_restore\": {\n      \"max\": 18411.469071626663,\n      \"min\": 18411.469071626663,\n      \"avg\": 18411.469071626663,\n      \"last\": 18411.469071626663,\n      \"last-5-avg\": 18411.469071626663,\n      \"last-10-avg\": 18411.469071626663\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088bb8725bfe89ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088bb8725bfe89ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1fade05450000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1fade05450000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1fade05450000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1fade05450000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d1fade05450000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d1fade05450000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00011\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031315f31315f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"11_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00011_11_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716603052.2543323,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8942148760330578,\n    \"timestamp\": 1716614925,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00011\",\n    \"date\": \"2024-05-25_07-28-45\",\n    \"time_this_iter_s\": 11873.09862613678,\n    \"time_total_s\": 11873.09862613678,\n    \"pid\": 265902,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11873.09862613678,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"11_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716614925.3547516,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8942148760330578,\n      \"min\": 0.8942148760330578,\n      \"avg\": 0.8942148760330578,\n      \"last\": 0.8942148760330578,\n      \"last-5-avg\": 0.8942148760330578,\n      \"last-10-avg\": 0.8942148760330578\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11873.09862613678,\n      \"min\": 11873.09862613678,\n      \"avg\": 11873.09862613678,\n      \"last\": 11873.09862613678,\n      \"last-5-avg\": 11873.09862613678,\n      \"last-10-avg\": 11873.09862613678\n    },\n    \"time_total_s\": {\n      \"max\": 11873.09862613678,\n      \"min\": 11873.09862613678,\n      \"avg\": 11873.09862613678,\n      \"last\": 11873.09862613678,\n      \"last-5-avg\": 11873.09862613678,\n      \"last-10-avg\": 11873.09862613678\n    },\n    \"time_since_restore\": {\n      \"max\": 11873.09862613678,\n      \"min\": 11873.09862613678,\n      \"avg\": 11873.09862613678,\n      \"last\": 11873.09862613678,\n      \"last-5-avg\": 11873.09862613678,\n      \"last-10-avg\": 11873.09862613678\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e3130584689dec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e3130584689dec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c7308c9fc80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c7308c9fc80000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c7308c9fc80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c7308c9fc80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c7308c9fc80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c7308c9fc80000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00022\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032325f32325f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e31305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"22_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00022_22_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.10_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716745754.2240102,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9002525252525252,\n    \"timestamp\": 1716763475,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00022\",\n    \"date\": \"2024-05-27_00-44-35\",\n    \"time_this_iter_s\": 7791.10347867012,\n    \"time_total_s\": 17721.533024072647,\n    \"pid\": 320678,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 17721.533024072647,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"22_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716763475.7606812,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9002525252525252,\n      \"min\": 0.7949604743083004,\n      \"avg\": 0.8476064997804128,\n      \"last\": 0.9002525252525252,\n      \"last-5-avg\": 0.8476064997804128,\n      \"last-10-avg\": 0.8476064997804128\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 9930.429545402527,\n      \"min\": 7791.10347867012,\n      \"avg\": 8860.766512036324,\n      \"last\": 7791.10347867012,\n      \"last-5-avg\": 8860.766512036324,\n      \"last-10-avg\": 8860.766512036324\n    },\n    \"time_total_s\": {\n      \"max\": 17721.533024072647,\n      \"min\": 9930.429545402527,\n      \"avg\": 13825.981284737587,\n      \"last\": 17721.533024072647,\n      \"last-5-avg\": 13825.981284737587,\n      \"last-10-avg\": 13825.981284737587\n    },\n    \"time_since_restore\": {\n      \"max\": 17721.533024072647,\n      \"min\": 9930.429545402527,\n      \"avg\": 13825.981284737587,\n      \"last\": 17721.533024072647,\n      \"last-5-avg\": 13825.981284737587,\n      \"last-10-avg\": 13825.981284737587\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089d89d8f25070e93f94869452946807680d4308793b4362deceec3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089d89d8f25070e93f94869452946807680d4308793b4362deceec3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c36536fb5800004740be6f1a7d940000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c36536fb5800004740be6f1a7d940000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c36536fb5800004740d14e621d110000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c36536fb5800004740d14e621d110000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c36536fb5800004740d14e621d110000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c36536fb5800004740d14e621d110000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00083\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038335f38335f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"83_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00083_83_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717517434.6585486,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8259187620889747,\n    \"timestamp\": 1717527507,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00083\",\n    \"date\": \"2024-06-04_20-58-27\",\n    \"time_this_iter_s\": 10072.979303359985,\n    \"time_total_s\": 10072.979303359985,\n    \"pid\": 623211,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10072.979303359985,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"83_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717527507.6398509,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8259187620889747,\n      \"min\": 0.8259187620889747,\n      \"avg\": 0.8259187620889747,\n      \"last\": 0.8259187620889747,\n      \"last-5-avg\": 0.8259187620889747,\n      \"last-10-avg\": 0.8259187620889747\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10072.979303359985,\n      \"min\": 10072.979303359985,\n      \"avg\": 10072.979303359985,\n      \"last\": 10072.979303359985,\n      \"last-5-avg\": 10072.979303359985,\n      \"last-10-avg\": 10072.979303359985\n    },\n    \"time_total_s\": {\n      \"max\": 10072.979303359985,\n      \"min\": 10072.979303359985,\n      \"avg\": 10072.979303359985,\n      \"last\": 10072.979303359985,\n      \"last-5-avg\": 10072.979303359985,\n      \"last-10-avg\": 10072.979303359985\n    },\n    \"time_since_restore\": {\n      \"max\": 10072.979303359985,\n      \"min\": 10072.979303359985,\n      \"avg\": 10072.979303359985,\n      \"last\": 10072.979303359985,\n      \"last-5-avg\": 10072.979303359985,\n      \"last-10-avg\": 10072.979303359985\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800660a2fed6dea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800660a2fed6dea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c3ac7d59d00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c3ac7d59d00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c3ac7d59d00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c3ac7d59d00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c3ac7d59d00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c3ac7d59d00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00092\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039325f39325f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"92_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00092_92_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717644555.1701272,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7359767891682786,\n    \"timestamp\": 1717658538,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00092\",\n    \"date\": \"2024-06-06_09-22-18\",\n    \"time_this_iter_s\": 9660.906580924988,\n    \"time_total_s\": 13983.664427518845,\n    \"pid\": 670682,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13983.664427518845,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"92_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717658538.8382576,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7359767891682786,\n      \"min\": 0.6920995670995671,\n      \"avg\": 0.7140381781339229,\n      \"last\": 0.7359767891682786,\n      \"last-5-avg\": 0.7140381781339229,\n      \"last-10-avg\": 0.7140381781339229\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 9660.906580924988,\n      \"min\": 4322.757846593857,\n      \"avg\": 6991.832213759422,\n      \"last\": 9660.906580924988,\n      \"last-5-avg\": 6991.832213759422,\n      \"last-10-avg\": 6991.832213759422\n    },\n    \"time_total_s\": {\n      \"max\": 13983.664427518845,\n      \"min\": 4322.757846593857,\n      \"avg\": 9153.21113705635,\n      \"last\": 13983.664427518845,\n      \"last-5-avg\": 9153.21113705635,\n      \"last-10-avg\": 9153.21113705635\n    },\n    \"time_since_restore\": {\n      \"max\": 13983.664427518845,\n      \"min\": 4322.757846593857,\n      \"avg\": 9153.21113705635,\n      \"last\": 13983.664427518845,\n      \"last-5-avg\": 9153.21113705635,\n      \"last-10-avg\": 9153.21113705635\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b896c8fdad25e63f94869452946807680d430893f802321f8de73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b896c8fdad25e63f94869452946807680d430893f802321f8de73f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b0e2c2023c00004740c2de740ad80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b0e2c2023c00004740c2de740ad80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b0e2c2023c00004740cb4fd50bf60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b0e2c2023c00004740cb4fd50bf60000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b0e2c2023c00004740cb4fd50bf60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b0e2c2023c00004740cb4fd50bf60000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00094\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039345f39345f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"94_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00094_94_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717668135.8052008,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7715097402597403,\n    \"timestamp\": 1717680120,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00094\",\n    \"date\": \"2024-06-06_15-22-00\",\n    \"time_this_iter_s\": 6100.16192483902,\n    \"time_total_s\": 11984.233498573303,\n    \"pid\": 681088,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11984.233498573303,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"94_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717680120.0424309,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7715097402597403,\n      \"min\": 0.6473063973063973,\n      \"avg\": 0.7094080687830688,\n      \"last\": 0.7715097402597403,\n      \"last-5-avg\": 0.7094080687830688,\n      \"last-10-avg\": 0.7094080687830688\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6100.16192483902,\n      \"min\": 5884.071573734283,\n      \"avg\": 5992.116749286652,\n      \"last\": 6100.16192483902,\n      \"last-5-avg\": 5992.116749286652,\n      \"last-10-avg\": 5992.116749286652\n    },\n    \"time_total_s\": {\n      \"max\": 11984.233498573303,\n      \"min\": 5884.071573734283,\n      \"avg\": 8934.152536153793,\n      \"last\": 11984.233498573303,\n      \"last-5-avg\": 8934.152536153793,\n      \"last-10-avg\": 8934.152536153793\n    },\n    \"time_since_restore\": {\n      \"max\": 11984.233498573303,\n      \"min\": 5884.071573734283,\n      \"avg\": 8934.152536153793,\n      \"last\": 11984.233498573303,\n      \"last-5-avg\": 8934.152536153793,\n      \"last-10-avg\": 8934.152536153793\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a85dde7bbb6e43f94869452946807680d4308d5c0de3135b0e83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a85dde7bbb6e43f94869452946807680d4308d5c0de3135b0e83f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6fc1252a800004740b7d42973e80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6fc1252a800004740b7d42973e80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6fc1252a800004740c7681de3480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6fc1252a800004740c7681de3480000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6fc1252a800004740c7681de3480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6fc1252a800004740c7681de3480000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00066\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036365f36365f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"66_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00066_66_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717317543.9660814,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.898030303030303,\n    \"timestamp\": 1717349856,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00066\",\n    \"date\": \"2024-06-02_19-37-36\",\n    \"time_this_iter_s\": 32312.043185710907,\n    \"time_total_s\": 32312.043185710907,\n    \"pid\": 547686,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 32312.043185710907,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"66_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717349856.0112147,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.898030303030303,\n      \"min\": 0.898030303030303,\n      \"avg\": 0.898030303030303,\n      \"last\": 0.898030303030303,\n      \"last-5-avg\": 0.898030303030303,\n      \"last-10-avg\": 0.898030303030303\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 32312.043185710907,\n      \"min\": 32312.043185710907,\n      \"avg\": 32312.043185710907,\n      \"last\": 32312.043185710907,\n      \"last-5-avg\": 32312.043185710907,\n      \"last-10-avg\": 32312.043185710907\n    },\n    \"time_total_s\": {\n      \"max\": 32312.043185710907,\n      \"min\": 32312.043185710907,\n      \"avg\": 32312.043185710907,\n      \"last\": 32312.043185710907,\n      \"last-5-avg\": 32312.043185710907,\n      \"last-10-avg\": 32312.043185710907\n    },\n    \"time_since_restore\": {\n      \"max\": 32312.043185710907,\n      \"min\": 32312.043185710907,\n      \"avg\": 32312.043185710907,\n      \"last\": 32312.043185710907,\n      \"last-5-avg\": 32312.043185710907,\n      \"last-10-avg\": 32312.043185710907\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bca0ca0baabcec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bca0ca0baabcec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740df8e02c38e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740df8e02c38e0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740df8e02c38e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740df8e02c38e0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740df8e02c38e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740df8e02c38e0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00081\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038315f38315f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"81_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00081_81_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717496592.1119726,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8509358288770053,\n    \"timestamp\": 1717506664,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00081\",\n    \"date\": \"2024-06-04_15-11-04\",\n    \"time_this_iter_s\": 3494.410248041153,\n    \"time_total_s\": 10072.491021871567,\n    \"pid\": 614572,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10072.491021871567,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"81_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717506664.606915,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8509358288770053,\n      \"min\": 0.7265625,\n      \"avg\": 0.7887491644385026,\n      \"last\": 0.8509358288770053,\n      \"last-5-avg\": 0.7887491644385026,\n      \"last-10-avg\": 0.7887491644385026\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6578.080773830414,\n      \"min\": 3494.410248041153,\n      \"avg\": 5036.245510935783,\n      \"last\": 3494.410248041153,\n      \"last-5-avg\": 5036.245510935783,\n      \"last-10-avg\": 5036.245510935783\n    },\n    \"time_total_s\": {\n      \"max\": 10072.491021871567,\n      \"min\": 6578.080773830414,\n      \"avg\": 8325.28589785099,\n      \"last\": 10072.491021871567,\n      \"last-5-avg\": 8325.28589785099,\n      \"last-10-avg\": 8325.28589785099\n    },\n    \"time_since_restore\": {\n      \"max\": 10072.491021871567,\n      \"min\": 6578.080773830414,\n      \"avg\": 8325.28589785099,\n      \"last\": 10072.491021871567,\n      \"last-5-avg\": 8325.28589785099,\n      \"last-10-avg\": 8325.28589785099\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000040e73f94869452946807680d43083aaf80c6dd3aeb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000040e73f94869452946807680d43083aaf80c6dd3aeb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b9b214ad9800004740ab4cd20c080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b9b214ad9800004740ab4cd20c080000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b9b214ad9800004740c3ac3ed9ce0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b9b214ad9800004740c3ac3ed9ce0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b9b214ad9800004740c3ac3ed9ce0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b9b214ad9800004740c3ac3ed9ce0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00004\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030345f345f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"4_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00004_4_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716522652.6256585,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8967497556207231,\n    \"timestamp\": 1716542339,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00004\",\n    \"date\": \"2024-05-24_11-18-59\",\n    \"time_this_iter_s\": 19686.804418563843,\n    \"time_total_s\": 19686.804418563843,\n    \"pid\": 224295,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 19686.804418563843,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"4_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716542339.432102,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8967497556207231,\n      \"min\": 0.8967497556207231,\n      \"avg\": 0.8967497556207231,\n      \"last\": 0.8967497556207231,\n      \"last-5-avg\": 0.8967497556207231,\n      \"last-10-avg\": 0.8967497556207231\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19686.804418563843,\n      \"min\": 19686.804418563843,\n      \"avg\": 19686.804418563843,\n      \"last\": 19686.804418563843,\n      \"last-5-avg\": 19686.804418563843,\n      \"last-10-avg\": 19686.804418563843\n    },\n    \"time_total_s\": {\n      \"max\": 19686.804418563843,\n      \"min\": 19686.804418563843,\n      \"avg\": 19686.804418563843,\n      \"last\": 19686.804418563843,\n      \"last-5-avg\": 19686.804418563843,\n      \"last-10-avg\": 19686.804418563843\n    },\n    \"time_since_restore\": {\n      \"max\": 19686.804418563843,\n      \"min\": 19686.804418563843,\n      \"avg\": 19686.804418563843,\n      \"last\": 19686.804418563843,\n      \"last-5-avg\": 19686.804418563843,\n      \"last-10-avg\": 19686.804418563843\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b0c8228b2cb2ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b0c8228b2cb2ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d339b37b980000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d339b37b980000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d339b37b980000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d339b37b980000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d339b37b980000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d339b37b980000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00051\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035315f35315f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"51_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00051_51_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717135887.0685644,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8731060606060606,\n    \"timestamp\": 1717151196,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00051\",\n    \"date\": \"2024-05-31_12-26-36\",\n    \"time_this_iter_s\": 3879.0649898052216,\n    \"time_total_s\": 15309.216080904007,\n    \"pid\": 479113,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15309.216080904007,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"51_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717151196.2889,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8731060606060606,\n      \"min\": 0.7926672384219553,\n      \"avg\": 0.8328866495140079,\n      \"last\": 0.8731060606060606,\n      \"last-5-avg\": 0.8328866495140079,\n      \"last-10-avg\": 0.8328866495140079\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11430.151091098785,\n      \"min\": 3879.0649898052216,\n      \"avg\": 7654.6080404520035,\n      \"last\": 3879.0649898052216,\n      \"last-5-avg\": 7654.6080404520035,\n      \"last-10-avg\": 7654.6080404520035\n    },\n    \"time_total_s\": {\n      \"max\": 15309.216080904007,\n      \"min\": 11430.151091098785,\n      \"avg\": 13369.683586001396,\n      \"last\": 15309.216080904007,\n      \"last-5-avg\": 13369.683586001396,\n      \"last-10-avg\": 13369.683586001396\n    },\n    \"time_since_restore\": {\n      \"max\": 15309.216080904007,\n      \"min\": 11430.151091098785,\n      \"avg\": 13369.683586001396,\n      \"last\": 15309.216080904007,\n      \"last-5-avg\": 13369.683586001396,\n      \"last-10-avg\": 13369.683586001396\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fc4034af875de93f94869452946807680d4308f0c1071f7cf0eb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fc4034af875de93f94869452946807680d4308f0c1071f7cf0eb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c6531356f400004740ae4e2146580000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c6531356f400004740ae4e2146580000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c6531356f400004740cde69ba88a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c6531356f400004740cde69ba88a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c6531356f400004740cde69ba88a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c6531356f400004740cde69ba88a0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00018\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031385f31385f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"18_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00018_18_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716682460.3162405,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8720095693779906,\n    \"timestamp\": 1716699269,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00018\",\n    \"date\": \"2024-05-26_06-54-29\",\n    \"time_this_iter_s\": 4095.116110801697,\n    \"time_total_s\": 16808.924738645554,\n    \"pid\": 296499,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16808.924738645554,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"18_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716699269.244558,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8720095693779906,\n      \"min\": 0.799884437596302,\n      \"avg\": 0.8359470034871463,\n      \"last\": 0.8720095693779906,\n      \"last-5-avg\": 0.8359470034871463,\n      \"last-10-avg\": 0.8359470034871463\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12713.808627843857,\n      \"min\": 4095.116110801697,\n      \"avg\": 8404.462369322777,\n      \"last\": 4095.116110801697,\n      \"last-5-avg\": 8404.462369322777,\n      \"last-10-avg\": 8404.462369322777\n    },\n    \"time_total_s\": {\n      \"max\": 16808.924738645554,\n      \"min\": 12713.808627843857,\n      \"avg\": 14761.366683244705,\n      \"last\": 16808.924738645554,\n      \"last-5-avg\": 14761.366683244705,\n      \"last-10-avg\": 14761.366683244705\n    },\n    \"time_since_restore\": {\n      \"max\": 16808.924738645554,\n      \"min\": 12713.808627843857,\n      \"avg\": 14761.366683244705,\n      \"last\": 16808.924738645554,\n      \"last-5-avg\": 14761.366683244705,\n      \"last-10-avg\": 14761.366683244705\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869c6813fa798e93f94869452946807680d430862e1c89c80e7eb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869c6813fa798e93f94869452946807680d430862e1c89c80e7eb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8d4e7811e00004740affe3b72e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8d4e7811e00004740affe3b72e00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8d4e7811e00004740d06a3b2eeb0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8d4e7811e00004740d06a3b2eeb0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8d4e7811e00004740d06a3b2eeb0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8d4e7811e00004740d06a3b2eeb0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00030\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033305f33305f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e31305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"30_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00030_30_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.10_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716837884.8262455,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7357954545454545,\n    \"timestamp\": 1716848888,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00030\",\n    \"date\": \"2024-05-28_00-28-08\",\n    \"time_this_iter_s\": 5174.23045539856,\n    \"time_total_s\": 11004.14712190628,\n    \"pid\": 355300,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11004.14712190628,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"30_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716848888.9772003,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7357954545454545,\n      \"min\": 0.6738215488215488,\n      \"avg\": 0.7048085016835016,\n      \"last\": 0.7357954545454545,\n      \"last-5-avg\": 0.7048085016835016,\n      \"last-10-avg\": 0.7048085016835016\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5829.916666507721,\n      \"min\": 5174.23045539856,\n      \"avg\": 5502.07356095314,\n      \"last\": 5174.23045539856,\n      \"last-5-avg\": 5502.07356095314,\n      \"last-10-avg\": 5502.07356095314\n    },\n    \"time_total_s\": {\n      \"max\": 11004.14712190628,\n      \"min\": 5829.916666507721,\n      \"avg\": 8417.031894207,\n      \"last\": 11004.14712190628,\n      \"last-5-avg\": 8417.031894207,\n      \"last-10-avg\": 8417.031894207\n    },\n    \"time_since_restore\": {\n      \"max\": 11004.14712190628,\n      \"min\": 5829.916666507721,\n      \"avg\": 8417.031894207,\n      \"last\": 11004.14712190628,\n      \"last-5-avg\": 8417.031894207,\n      \"last-10-avg\": 8417.031894207\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873ea7035f28fe53f94869452946807680d43088b2ebae8a28be73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430873ea7035f28fe53f94869452946807680d43088b2ebae8a28be73f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6c5eaaaa800004740b4363aff200000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6c5eaaaa800004740b4363aff200000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6c5eaaaa800004740c57e12d4e40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6c5eaaaa800004740c57e12d4e40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6c5eaaaa800004740c57e12d4e40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6c5eaaaa800004740c57e12d4e40000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00041\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034315f34315f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"41_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00041_41_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717001209.2282639,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9158130601792575,\n    \"timestamp\": 1717016364,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00041\",\n    \"date\": \"2024-05-29_22-59-24\",\n    \"time_this_iter_s\": 15155.508346796036,\n    \"time_total_s\": 15155.508346796036,\n    \"pid\": 418618,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15155.508346796036,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"41_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717016364.7387662,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9158130601792575,\n      \"min\": 0.9158130601792575,\n      \"avg\": 0.9158130601792575,\n      \"last\": 0.9158130601792575,\n      \"last-5-avg\": 0.9158130601792575,\n      \"last-10-avg\": 0.9158130601792575\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15155.508346796036,\n      \"min\": 15155.508346796036,\n      \"avg\": 15155.508346796036,\n      \"last\": 15155.508346796036,\n      \"last-5-avg\": 15155.508346796036,\n      \"last-10-avg\": 15155.508346796036\n    },\n    \"time_total_s\": {\n      \"max\": 15155.508346796036,\n      \"min\": 15155.508346796036,\n      \"avg\": 15155.508346796036,\n      \"last\": 15155.508346796036,\n      \"last-5-avg\": 15155.508346796036,\n      \"last-10-avg\": 15155.508346796036\n    },\n    \"time_since_restore\": {\n      \"max\": 15155.508346796036,\n      \"min\": 15155.508346796036,\n      \"avg\": 15155.508346796036,\n      \"last\": 15155.508346796036,\n      \"last-5-avg\": 15155.508346796036,\n      \"last-10-avg\": 15155.508346796036\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e306d730574eed3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e306d730574eed3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cd99c111820000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cd99c111820000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cd99c111820000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cd99c111820000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cd99c111820000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cd99c111820000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00064\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036345f36345f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"64_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00064_64_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717287198.322295,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8787081339712917,\n    \"timestamp\": 1717306683,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00064\",\n    \"date\": \"2024-06-02_07-38-03\",\n    \"time_this_iter_s\": 19485.043239355087,\n    \"time_total_s\": 19485.043239355087,\n    \"pid\": 536207,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 19485.043239355087,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"64_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717306683.3674912,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8787081339712917,\n      \"min\": 0.8787081339712917,\n      \"avg\": 0.8787081339712917,\n      \"last\": 0.8787081339712917,\n      \"last-5-avg\": 0.8787081339712917,\n      \"last-10-avg\": 0.8787081339712917\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 19485.043239355087,\n      \"min\": 19485.043239355087,\n      \"avg\": 19485.043239355087,\n      \"last\": 19485.043239355087,\n      \"last-5-avg\": 19485.043239355087,\n      \"last-10-avg\": 19485.043239355087\n    },\n    \"time_total_s\": {\n      \"max\": 19485.043239355087,\n      \"min\": 19485.043239355087,\n      \"avg\": 19485.043239355087,\n      \"last\": 19485.043239355087,\n      \"last-5-avg\": 19485.043239355087,\n      \"last-10-avg\": 19485.043239355087\n    },\n    \"time_since_restore\": {\n      \"max\": 19485.043239355087,\n      \"min\": 19485.043239355087,\n      \"avg\": 19485.043239355087,\n      \"last\": 19485.043239355087,\n      \"last-5-avg\": 19485.043239355087,\n      \"last-10-avg\": 19485.043239355087\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a594485601eec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082a594485601eec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d30742c46f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d30742c46f0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d30742c46f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d30742c46f0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d30742c46f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d30742c46f0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00016\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031365f31365f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e313030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"16_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00016_16_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716652198.0240033,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8192424242424242,\n    \"timestamp\": 1716667624,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00016\",\n    \"date\": \"2024-05-25_22-07-04\",\n    \"time_this_iter_s\": 15426.477827072144,\n    \"time_total_s\": 15426.477827072144,\n    \"pid\": 285393,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15426.477827072144,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"16_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716667624.5036328,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8192424242424242,\n      \"min\": 0.8192424242424242,\n      \"avg\": 0.8192424242424242,\n      \"last\": 0.8192424242424242,\n      \"last-5-avg\": 0.8192424242424242,\n      \"last-10-avg\": 0.8192424242424242\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15426.477827072144,\n      \"min\": 15426.477827072144,\n      \"avg\": 15426.477827072144,\n      \"last\": 15426.477827072144,\n      \"last-5-avg\": 15426.477827072144,\n      \"last-10-avg\": 15426.477827072144\n    },\n    \"time_total_s\": {\n      \"max\": 15426.477827072144,\n      \"min\": 15426.477827072144,\n      \"avg\": 15426.477827072144,\n      \"last\": 15426.477827072144,\n      \"last-5-avg\": 15426.477827072144,\n      \"last-10-avg\": 15426.477827072144\n    },\n    \"time_since_restore\": {\n      \"max\": 15426.477827072144,\n      \"min\": 15426.477827072144,\n      \"avg\": 15426.477827072144,\n      \"last\": 15426.477827072144,\n      \"last-5-avg\": 15426.477827072144,\n      \"last-10-avg\": 15426.477827072144\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837be73e33b37ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837be73e33b37ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce213d29700000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce213d29700000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce213d29700000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce213d29700000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce213d29700000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce213d29700000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00012\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031325f31325f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"12_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00012_12_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716614927.373437,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8492647058823529,\n    \"timestamp\": 1716621951,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00012\",\n    \"date\": \"2024-05-25_09-25-51\",\n    \"time_this_iter_s\": 7023.8958151340485,\n    \"time_total_s\": 7023.8958151340485,\n    \"pid\": 270705,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 7023.8958151340485,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"12_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716621951.2711115,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8492647058823529,\n      \"min\": 0.8492647058823529,\n      \"avg\": 0.8492647058823529,\n      \"last\": 0.8492647058823529,\n      \"last-5-avg\": 0.8492647058823529,\n      \"last-10-avg\": 0.8492647058823529\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7023.8958151340485,\n      \"min\": 7023.8958151340485,\n      \"avg\": 7023.8958151340485,\n      \"last\": 7023.8958151340485,\n      \"last-5-avg\": 7023.8958151340485,\n      \"last-10-avg\": 7023.8958151340485\n    },\n    \"time_total_s\": {\n      \"max\": 7023.8958151340485,\n      \"min\": 7023.8958151340485,\n      \"avg\": 7023.8958151340485,\n      \"last\": 7023.8958151340485,\n      \"last-5-avg\": 7023.8958151340485,\n      \"last-10-avg\": 7023.8958151340485\n    },\n    \"time_since_restore\": {\n      \"max\": 7023.8958151340485,\n      \"min\": 7023.8958151340485,\n      \"avg\": 7023.8958151340485,\n      \"last\": 7023.8958151340485,\n      \"last-5-avg\": 7023.8958151340485,\n      \"last-10-avg\": 7023.8958151340485\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082d2d2d2d2d2deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082d2d2d2d2d2deb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb6fe554240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb6fe554240000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb6fe554240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb6fe554240000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb6fe554240000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb6fe554240000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00048\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034385f34385f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"48_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00048_48_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717092232.2928119,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8446969696969697,\n    \"timestamp\": 1717109432,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00048\",\n    \"date\": \"2024-05-31_00-50-32\",\n    \"time_this_iter_s\": 3727.8291301727295,\n    \"time_total_s\": 17200.105230808258,\n    \"pid\": 462696,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 17200.105230808258,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"48_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717109432.4044197,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8446969696969697,\n      \"min\": 0.7648601398601399,\n      \"avg\": 0.8047785547785549,\n      \"last\": 0.8446969696969697,\n      \"last-5-avg\": 0.8047785547785549,\n      \"last-10-avg\": 0.8047785547785549\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 13472.276100635529,\n      \"min\": 3727.8291301727295,\n      \"avg\": 8600.052615404129,\n      \"last\": 3727.8291301727295,\n      \"last-5-avg\": 8600.052615404129,\n      \"last-10-avg\": 8600.052615404129\n    },\n    \"time_total_s\": {\n      \"max\": 17200.105230808258,\n      \"min\": 13472.276100635529,\n      \"avg\": 15336.190665721893,\n      \"last\": 17200.105230808258,\n      \"last-5-avg\": 15336.190665721893,\n      \"last-10-avg\": 15336.190665721893\n    },\n    \"time_since_restore\": {\n      \"max\": 17200.105230808258,\n      \"min\": 13472.276100635529,\n      \"avg\": 15336.190665721893,\n      \"last\": 17200.105230808258,\n      \"last-5-avg\": 15336.190665721893,\n      \"last-10-avg\": 15336.190665721893\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083fd3d6f8bb79e83f94869452946807680d4308081f7cf0c107eb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083fd3d6f8bb79e83f94869452946807680d4308081f7cf0c107eb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ca5023574400004740ad1fa883c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ca5023574400004740ad1fa883c00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ca5023574400004740d0cc06bc1a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ca5023574400004740d0cc06bc1a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740ca5023574400004740d0cc06bc1a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740ca5023574400004740d0cc06bc1a0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00067\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036375f36375f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"67_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00067_67_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717349857.9147308,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8775826446280991,\n    \"timestamp\": 1717359322,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00067\",\n    \"date\": \"2024-06-02_22-15-22\",\n    \"time_this_iter_s\": 9464.869913816452,\n    \"time_total_s\": 9464.869913816452,\n    \"pid\": 559638,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9464.869913816452,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"67_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717359322.7865403,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8775826446280991,\n      \"min\": 0.8775826446280991,\n      \"avg\": 0.8775826446280991,\n      \"last\": 0.8775826446280991,\n      \"last-5-avg\": 0.8775826446280991,\n      \"last-10-avg\": 0.8775826446280991\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 9464.869913816452,\n      \"min\": 9464.869913816452,\n      \"avg\": 9464.869913816452,\n      \"last\": 9464.869913816452,\n      \"last-5-avg\": 9464.869913816452,\n      \"last-10-avg\": 9464.869913816452\n    },\n    \"time_total_s\": {\n      \"max\": 9464.869913816452,\n      \"min\": 9464.869913816452,\n      \"avg\": 9464.869913816452,\n      \"last\": 9464.869913816452,\n      \"last-5-avg\": 9464.869913816452,\n      \"last-10-avg\": 9464.869913816452\n    },\n    \"time_since_restore\": {\n      \"max\": 9464.869913816452,\n      \"min\": 9464.869913816452,\n      \"avg\": 9464.869913816452,\n      \"last\": 9464.869913816452,\n      \"last-5-avg\": 9464.869913816452,\n      \"last-10-avg\": 9464.869913816452\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843e0c6322815ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843e0c6322815ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c27c6f59560000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c27c6f59560000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c27c6f59560000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c27c6f59560000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c27c6f59560000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c27c6f59560000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00033\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033335f33335f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"33_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00033_33_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716886913.8054209,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8791461916461917,\n    \"timestamp\": 1716902215,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00033\",\n    \"date\": \"2024-05-28_15-16-55\",\n    \"time_this_iter_s\": 15301.842490434647,\n    \"time_total_s\": 15301.842490434647,\n    \"pid\": 373816,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15301.842490434647,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"33_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716902215.6500316,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8791461916461917,\n      \"min\": 0.8791461916461917,\n      \"avg\": 0.8791461916461917,\n      \"last\": 0.8791461916461917,\n      \"last-5-avg\": 0.8791461916461917,\n      \"last-10-avg\": 0.8791461916461917\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15301.842490434647,\n      \"min\": 15301.842490434647,\n      \"avg\": 15301.842490434647,\n      \"last\": 15301.842490434647,\n      \"last-5-avg\": 15301.842490434647,\n      \"last-10-avg\": 15301.842490434647\n    },\n    \"time_total_s\": {\n      \"max\": 15301.842490434647,\n      \"min\": 15301.842490434647,\n      \"avg\": 15301.842490434647,\n      \"last\": 15301.842490434647,\n      \"last-5-avg\": 15301.842490434647,\n      \"last-10-avg\": 15301.842490434647\n    },\n    \"time_since_restore\": {\n      \"max\": 15301.842490434647,\n      \"min\": 15301.842490434647,\n      \"avg\": 15301.842490434647,\n      \"last\": 15301.842490434647,\n      \"last-5-avg\": 15301.842490434647,\n      \"last-10-avg\": 15301.842490434647\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837bfb031f721ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430837bfb031f721ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cde2ebd6ba0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cde2ebd6ba0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cde2ebd6ba0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cde2ebd6ba0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cde2ebd6ba0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cde2ebd6ba0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00069\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036395f36395f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"69_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00069_69_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717372494.4733257,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8420454545454545,\n    \"timestamp\": 1717376629,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00069\",\n    \"date\": \"2024-06-03_03-03-49\",\n    \"time_this_iter_s\": 4134.975585699081,\n    \"time_total_s\": 4134.975585699081,\n    \"pid\": 567866,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 4134.975585699081,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"69_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717376629.4509354,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8420454545454545,\n      \"min\": 0.8420454545454545,\n      \"avg\": 0.8420454545454545,\n      \"last\": 0.8420454545454545,\n      \"last-5-avg\": 0.8420454545454545,\n      \"last-10-avg\": 0.8420454545454545\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4134.975585699081,\n      \"min\": 4134.975585699081,\n      \"avg\": 4134.975585699081,\n      \"last\": 4134.975585699081,\n      \"last-5-avg\": 4134.975585699081,\n      \"last-10-avg\": 4134.975585699081\n    },\n    \"time_total_s\": {\n      \"max\": 4134.975585699081,\n      \"min\": 4134.975585699081,\n      \"avg\": 4134.975585699081,\n      \"last\": 4134.975585699081,\n      \"last-5-avg\": 4134.975585699081,\n      \"last-10-avg\": 4134.975585699081\n    },\n    \"time_since_restore\": {\n      \"max\": 4134.975585699081,\n      \"min\": 4134.975585699081,\n      \"avg\": 4134.975585699081,\n      \"last\": 4134.975585699081,\n      \"last-5-avg\": 4134.975585699081,\n      \"last-10-avg\": 4134.975585699081\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f294204f09f2ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f294204f09f2ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b026f9bffc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b026f9bffc0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b026f9bffc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b026f9bffc0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b026f9bffc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b026f9bffc0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00042\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034325f34325f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"42_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00042_42_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717016367.6358714,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8551136363636364,\n    \"timestamp\": 1717023497,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00042\",\n    \"date\": \"2024-05-30_00-58-17\",\n    \"time_this_iter_s\": 7129.643869161606,\n    \"time_total_s\": 7129.643869161606,\n    \"pid\": 424210,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 7129.643869161606,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"42_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717023497.2817914,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8551136363636364,\n      \"min\": 0.8551136363636364,\n      \"avg\": 0.8551136363636364,\n      \"last\": 0.8551136363636364,\n      \"last-5-avg\": 0.8551136363636364,\n      \"last-10-avg\": 0.8551136363636364\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7129.643869161606,\n      \"min\": 7129.643869161606,\n      \"avg\": 7129.643869161606,\n      \"last\": 7129.643869161606,\n      \"last-5-avg\": 7129.643869161606,\n      \"last-10-avg\": 7129.643869161606\n    },\n    \"time_total_s\": {\n      \"max\": 7129.643869161606,\n      \"min\": 7129.643869161606,\n      \"avg\": 7129.643869161606,\n      \"last\": 7129.643869161606,\n      \"last-5-avg\": 7129.643869161606,\n      \"last-10-avg\": 7129.643869161606\n    },\n    \"time_since_restore\": {\n      \"max\": 7129.643869161606,\n      \"min\": 7129.643869161606,\n      \"avg\": 7129.643869161606,\n      \"last\": 7129.643869161606,\n      \"last-5-avg\": 7129.643869161606,\n      \"last-10-avg\": 7129.643869161606\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085d74d145175deb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085d74d145175deb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbd9a4d49c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbd9a4d49c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbd9a4d49c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbd9a4d49c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbd9a4d49c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbd9a4d49c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00027\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032375f32375f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"27_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00027_27_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716801347.6085,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8149350649350648,\n    \"timestamp\": 1716814700,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00027\",\n    \"date\": \"2024-05-27_14-58-20\",\n    \"time_this_iter_s\": 7535.638502836227,\n    \"time_total_s\": 13352.917387247086,\n    \"pid\": 341320,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13352.917387247086,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"27_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716814700.5297287,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8149350649350648,\n      \"min\": 0.7319023569023572,\n      \"avg\": 0.773418710918711,\n      \"last\": 0.8149350649350648,\n      \"last-5-avg\": 0.773418710918711,\n      \"last-10-avg\": 0.773418710918711\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7535.638502836227,\n      \"min\": 5817.278884410858,\n      \"avg\": 6676.458693623543,\n      \"last\": 7535.638502836227,\n      \"last-5-avg\": 6676.458693623543,\n      \"last-10-avg\": 6676.458693623543\n    },\n    \"time_total_s\": {\n      \"max\": 13352.917387247086,\n      \"min\": 5817.278884410858,\n      \"avg\": 9585.098135828972,\n      \"last\": 13352.917387247086,\n      \"last-5-avg\": 9585.098135828972,\n      \"last-10-avg\": 9585.098135828972\n    },\n    \"time_since_restore\": {\n      \"max\": 13352.917387247086,\n      \"min\": 5817.278884410858,\n      \"avg\": 9585.098135828972,\n      \"last\": 13352.917387247086,\n      \"last-5-avg\": 9585.098135828972,\n      \"last-10-avg\": 9585.098135828972\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a759d87dbe6be73f94869452946807680d4308ca4f88b3f213ea3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a759d87dbe6be73f94869452946807680d4308ca4f88b3f213ea3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b94764f800004740bd6fa374ec0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b94764f800004740bd6fa374ec0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b94764f800004740ca14756cf20000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b94764f800004740ca14756cf20000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b94764f800004740ca14756cf20000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b94764f800004740ca14756cf20000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00015\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031355f31355f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e31305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"15_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00015_15_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.10_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716641624.142506,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9044526901669758,\n    \"timestamp\": 1716652195,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00015\",\n    \"date\": \"2024-05-25_17-49-55\",\n    \"time_this_iter_s\": 10571.59408736229,\n    \"time_total_s\": 10571.59408736229,\n    \"pid\": 280552,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10571.59408736229,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"15_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716652195.7384403,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9044526901669758,\n      \"min\": 0.9044526901669758,\n      \"avg\": 0.9044526901669758,\n      \"last\": 0.9044526901669758,\n      \"last-5-avg\": 0.9044526901669758,\n      \"last-10-avg\": 0.9044526901669758\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10571.59408736229,\n      \"min\": 10571.59408736229,\n      \"avg\": 10571.59408736229,\n      \"last\": 10571.59408736229,\n      \"last-5-avg\": 10571.59408736229,\n      \"last-10-avg\": 10571.59408736229\n    },\n    \"time_total_s\": {\n      \"max\": 10571.59408736229,\n      \"min\": 10571.59408736229,\n      \"avg\": 10571.59408736229,\n      \"last\": 10571.59408736229,\n      \"last-5-avg\": 10571.59408736229,\n      \"last-10-avg\": 10571.59408736229\n    },\n    \"time_since_restore\": {\n      \"max\": 10571.59408736229,\n      \"min\": 10571.59408736229,\n      \"avg\": 10571.59408736229,\n      \"last\": 10571.59408736229,\n      \"last-5-avg\": 10571.59408736229,\n      \"last-10-avg\": 10571.59408736229\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f67ba1c446f1ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f67ba1c446f1ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c4a5cc0b0e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c4a5cc0b0e0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c4a5cc0b0e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c4a5cc0b0e0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c4a5cc0b0e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c4a5cc0b0e0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00040\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034305f34305f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"40_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00040_40_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716995473.352142,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8522727272727274,\n    \"timestamp\": 1717001207,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00040\",\n    \"date\": \"2024-05-29_18-46-47\",\n    \"time_this_iter_s\": 5733.67662525177,\n    \"time_total_s\": 5733.67662525177,\n    \"pid\": 416449,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 5733.67662525177,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"40_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717001207.0305228,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8522727272727274,\n      \"min\": 0.8522727272727274,\n      \"avg\": 0.8522727272727274,\n      \"last\": 0.8522727272727274,\n      \"last-5-avg\": 0.8522727272727274,\n      \"last-10-avg\": 0.8522727272727274\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5733.67662525177,\n      \"min\": 5733.67662525177,\n      \"avg\": 5733.67662525177,\n      \"last\": 5733.67662525177,\n      \"last-5-avg\": 5733.67662525177,\n      \"last-10-avg\": 5733.67662525177\n    },\n    \"time_total_s\": {\n      \"max\": 5733.67662525177,\n      \"min\": 5733.67662525177,\n      \"avg\": 5733.67662525177,\n      \"last\": 5733.67662525177,\n      \"last-5-avg\": 5733.67662525177,\n      \"last-10-avg\": 5733.67662525177\n    },\n    \"time_since_restore\": {\n      \"max\": 5733.67662525177,\n      \"min\": 5733.67662525177,\n      \"avg\": 5733.67662525177,\n      \"last\": 5733.67662525177,\n      \"last-5-avg\": 5733.67662525177,\n      \"last-10-avg\": 5733.67662525177\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430847175d74d145eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430847175d74d145eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b665ad37500000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b665ad37500000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b665ad37500000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b665ad37500000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b665ad37500000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b665ad37500000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00082\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038325f38325f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"82_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00082_82_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717506667.1767488,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8218181818181819,\n    \"timestamp\": 1717517432,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00082\",\n    \"date\": \"2024-06-04_18-10-32\",\n    \"time_this_iter_s\": 10765.074086666107,\n    \"time_total_s\": 10765.074086666107,\n    \"pid\": 618555,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10765.074086666107,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"82_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717517432.252825,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8218181818181819,\n      \"min\": 0.8218181818181819,\n      \"avg\": 0.8218181818181819,\n      \"last\": 0.8218181818181819,\n      \"last-5-avg\": 0.8218181818181819,\n      \"last-10-avg\": 0.8218181818181819\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 10765.074086666107,\n      \"min\": 10765.074086666107,\n      \"avg\": 10765.074086666107,\n      \"last\": 10765.074086666107,\n      \"last-5-avg\": 10765.074086666107,\n      \"last-10-avg\": 10765.074086666107\n    },\n    \"time_total_s\": {\n      \"max\": 10765.074086666107,\n      \"min\": 10765.074086666107,\n      \"avg\": 10765.074086666107,\n      \"last\": 10765.074086666107,\n      \"last-5-avg\": 10765.074086666107,\n      \"last-10-avg\": 10765.074086666107\n    },\n    \"time_since_restore\": {\n      \"max\": 10765.074086666107,\n      \"min\": 10765.074086666107,\n      \"avg\": 10765.074086666107,\n      \"last\": 10765.074086666107,\n      \"last-5-avg\": 10765.074086666107,\n      \"last-10-avg\": 10765.074086666107\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084d5ac5a4554cea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084d5ac5a4554cea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c506897bac0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c506897bac0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c506897bac0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c506897bac0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c506897bac0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c506897bac0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00053\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035335f35335f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"53_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00053_53_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717162934.2031355,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8033826638477801,\n    \"timestamp\": 1717171784,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00053\",\n    \"date\": \"2024-05-31_18-09-44\",\n    \"time_this_iter_s\": 8849.844603300095,\n    \"time_total_s\": 8849.844603300095,\n    \"pid\": 490033,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8849.844603300095,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"53_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717171784.049704,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8033826638477801,\n      \"min\": 0.8033826638477801,\n      \"avg\": 0.8033826638477801,\n      \"last\": 0.8033826638477801,\n      \"last-5-avg\": 0.8033826638477801,\n      \"last-10-avg\": 0.8033826638477801\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8849.844603300095,\n      \"min\": 8849.844603300095,\n      \"avg\": 8849.844603300095,\n      \"last\": 8849.844603300095,\n      \"last-5-avg\": 8849.844603300095,\n      \"last-10-avg\": 8849.844603300095\n    },\n    \"time_total_s\": {\n      \"max\": 8849.844603300095,\n      \"min\": 8849.844603300095,\n      \"avg\": 8849.844603300095,\n      \"last\": 8849.844603300095,\n      \"last-5-avg\": 8849.844603300095,\n      \"last-10-avg\": 8849.844603300095\n    },\n    \"time_since_restore\": {\n      \"max\": 8849.844603300095,\n      \"min\": 8849.844603300095,\n      \"avg\": 8849.844603300095,\n      \"last\": 8849.844603300095,\n      \"last-5-avg\": 8849.844603300095,\n      \"last-10-avg\": 8849.844603300095\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430856c96c8f4fb5e93f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430856c96c8f4fb5e93f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c148ec1bf60000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c148ec1bf60000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c148ec1bf60000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c148ec1bf60000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c148ec1bf60000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c148ec1bf60000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00002\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030325f325f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"2_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00002_2_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716496416.9122064,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8837072018890201,\n    \"timestamp\": 1716513174,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00002\",\n    \"date\": \"2024-05-24_03-12-54\",\n    \"time_this_iter_s\": 16757.853830575943,\n    \"time_total_s\": 16757.853830575943,\n    \"pid\": 212187,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16757.853830575943,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"2_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716513174.7677991,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8837072018890201,\n      \"min\": 0.8837072018890201,\n      \"avg\": 0.8837072018890201,\n      \"last\": 0.8837072018890201,\n      \"last-5-avg\": 0.8837072018890201,\n      \"last-10-avg\": 0.8837072018890201\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16757.853830575943,\n      \"min\": 16757.853830575943,\n      \"avg\": 16757.853830575943,\n      \"last\": 16757.853830575943,\n      \"last-5-avg\": 16757.853830575943,\n      \"last-10-avg\": 16757.853830575943\n    },\n    \"time_total_s\": {\n      \"max\": 16757.853830575943,\n      \"min\": 16757.853830575943,\n      \"avg\": 16757.853830575943,\n      \"last\": 16757.853830575943,\n      \"last-5-avg\": 16757.853830575943,\n      \"last-10-avg\": 16757.853830575943\n    },\n    \"time_since_restore\": {\n      \"max\": 16757.853830575943,\n      \"min\": 16757.853830575943,\n      \"avg\": 16757.853830575943,\n      \"last\": 16757.853830575943,\n      \"last-5-avg\": 16757.853830575943,\n      \"last-10-avg\": 16757.853830575943\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dd4b6b535447ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dd4b6b535447ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d05d76a5290000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d05d76a5290000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d05d76a5290000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d05d76a5290000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d05d76a5290000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d05d76a5290000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00037\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033375f33375f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"37_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00037_37_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716966335.720803,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8597027972027973,\n    \"timestamp\": 1716971713,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00037\",\n    \"date\": \"2024-05-29_10-35-13\",\n    \"time_this_iter_s\": 5377.364926338196,\n    \"time_total_s\": 5377.364926338196,\n    \"pid\": 404753,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 5377.364926338196,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"37_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716971713.087732,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8597027972027973,\n      \"min\": 0.8597027972027973,\n      \"avg\": 0.8597027972027973,\n      \"last\": 0.8597027972027973,\n      \"last-5-avg\": 0.8597027972027973,\n      \"last-10-avg\": 0.8597027972027973\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5377.364926338196,\n      \"min\": 5377.364926338196,\n      \"avg\": 5377.364926338196,\n      \"last\": 5377.364926338196,\n      \"last-5-avg\": 5377.364926338196,\n      \"last-10-avg\": 5377.364926338196\n    },\n    \"time_total_s\": {\n      \"max\": 5377.364926338196,\n      \"min\": 5377.364926338196,\n      \"avg\": 5377.364926338196,\n      \"last\": 5377.364926338196,\n      \"last-5-avg\": 5377.364926338196,\n      \"last-10-avg\": 5377.364926338196\n    },\n    \"time_since_restore\": {\n      \"max\": 5377.364926338196,\n      \"min\": 5377.364926338196,\n      \"avg\": 5377.364926338196,\n      \"last\": 5377.364926338196,\n      \"last-5-avg\": 5377.364926338196,\n      \"last-10-avg\": 5377.364926338196\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e680c870af82eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e680c870af82eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b5015d6bd00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b5015d6bd00000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b5015d6bd00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b5015d6bd00000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b5015d6bd00000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b5015d6bd00000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00085\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038355f38355f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"85_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00085_85_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717543805.7171514,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8622542997542997,\n    \"timestamp\": 1717559072,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00085\",\n    \"date\": \"2024-06-05_05-44-32\",\n    \"time_this_iter_s\": 15266.651933193207,\n    \"time_total_s\": 15266.651933193207,\n    \"pid\": 632949,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15266.651933193207,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"85_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717559072.370972,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8622542997542997,\n      \"min\": 0.8622542997542997,\n      \"avg\": 0.8622542997542997,\n      \"last\": 0.8622542997542997,\n      \"last-5-avg\": 0.8622542997542997,\n      \"last-10-avg\": 0.8622542997542997\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15266.651933193207,\n      \"min\": 15266.651933193207,\n      \"avg\": 15266.651933193207,\n      \"last\": 15266.651933193207,\n      \"last-5-avg\": 15266.651933193207,\n      \"last-10-avg\": 15266.651933193207\n    },\n    \"time_total_s\": {\n      \"max\": 15266.651933193207,\n      \"min\": 15266.651933193207,\n      \"avg\": 15266.651933193207,\n      \"last\": 15266.651933193207,\n      \"last-5-avg\": 15266.651933193207,\n      \"last-10-avg\": 15266.651933193207\n    },\n    \"time_since_restore\": {\n      \"max\": 15266.651933193207,\n      \"min\": 15266.651933193207,\n      \"avg\": 15266.651933193207,\n      \"last\": 15266.651933193207,\n      \"last-5-avg\": 15266.651933193207,\n      \"last-10-avg\": 15266.651933193207\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890f648549697eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890f648549697eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cdd153728c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cdd153728c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cdd153728c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cdd153728c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cdd153728c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cdd153728c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00029\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032395f32395f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"29_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00029_29_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716824275.5142086,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.6960227272727273,\n    \"timestamp\": 1716837882,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00029\",\n    \"date\": \"2024-05-27_21-24-42\",\n    \"time_this_iter_s\": 6596.481989145279,\n    \"time_total_s\": 13607.357372522354,\n    \"pid\": 349609,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 13607.357372522354,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"29_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716837882.8754315,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6960227272727273,\n      \"min\": 0.6734625668449198,\n      \"avg\": 0.6847426470588236,\n      \"last\": 0.6960227272727273,\n      \"last-5-avg\": 0.6847426470588236,\n      \"last-10-avg\": 0.6847426470588236\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7010.875383377075,\n      \"min\": 6596.481989145279,\n      \"avg\": 6803.678686261177,\n      \"last\": 6596.481989145279,\n      \"last-5-avg\": 6803.678686261177,\n      \"last-10-avg\": 6803.678686261177\n    },\n    \"time_total_s\": {\n      \"max\": 13607.357372522354,\n      \"min\": 7010.875383377075,\n      \"avg\": 10309.116377949715,\n      \"last\": 13607.357372522354,\n      \"last-5-avg\": 10309.116377949715,\n      \"last-10-avg\": 10309.116377949715\n    },\n    \"time_since_restore\": {\n      \"max\": 13607.357372522354,\n      \"min\": 7010.875383377075,\n      \"avg\": 10309.116377949715,\n      \"last\": 13607.357372522354,\n      \"last-5-avg\": 10309.116377949715,\n      \"last-10-avg\": 10309.116377949715\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088dbb755e018de53f94869452946807680d430846175d74d145e63f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088dbb755e018de53f94869452946807680d430846175d74d145e63f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bb62e0192000004740b9c47b63a40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bb62e0192000004740b9c47b63a40000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bb62e0192000004740ca93adbe620000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bb62e0192000004740ca93adbe620000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bb62e0192000004740ca93adbe620000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bb62e0192000004740ca93adbe620000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00090\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039305f39305f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"90_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00090_90_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717614012.4860466,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8174715909090908,\n    \"timestamp\": 1717623268,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00090\",\n    \"date\": \"2024-06-05_23-34-28\",\n    \"time_this_iter_s\": 3445.295881509781,\n    \"time_total_s\": 9255.747663021088,\n    \"pid\": 659892,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9255.747663021088,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"90_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717623268.2376301,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8174715909090908,\n      \"min\": 0.7904040404040403,\n      \"avg\": 0.8039378156565655,\n      \"last\": 0.8174715909090908,\n      \"last-5-avg\": 0.8039378156565655,\n      \"last-10-avg\": 0.8039378156565655\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5810.451781511307,\n      \"min\": 3445.295881509781,\n      \"avg\": 4627.873831510544,\n      \"last\": 3445.295881509781,\n      \"last-5-avg\": 4627.873831510544,\n      \"last-10-avg\": 4627.873831510544\n    },\n    \"time_total_s\": {\n      \"max\": 9255.747663021088,\n      \"min\": 5810.451781511307,\n      \"avg\": 7533.099722266197,\n      \"last\": 9255.747663021088,\n      \"last-5-avg\": 7533.099722266197,\n      \"last-10-avg\": 7533.099722266197\n    },\n    \"time_since_restore\": {\n      \"max\": 9255.747663021088,\n      \"min\": 5810.451781511307,\n      \"avg\": 7533.099722266197,\n      \"last\": 9255.747663021088,\n      \"last-5-avg\": 7533.099722266197,\n      \"last-10-avg\": 7533.099722266197\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f52b056afd4ae93f94869452946807680d4308e8a28b2eba28ea3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f52b056afd4ae93f94869452946807680d4308e8a28b2eba28ea3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b273a7f400004740aaea977dc80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b273a7f400004740aaea977dc80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b273a7f400004740c213dfb36c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b273a7f400004740c213dfb36c0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b6b273a7f400004740c213dfb36c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b6b273a7f400004740c213dfb36c0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00013\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031335f31335f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"13_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00013_13_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716621953.643501,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9014530551415797,\n    \"timestamp\": 1716634514,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00013\",\n    \"date\": \"2024-05-25_12-55-14\",\n    \"time_this_iter_s\": 12561.126052856445,\n    \"time_total_s\": 12561.126052856445,\n    \"pid\": 273308,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 12561.126052856445,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"13_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716634514.7713604,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9014530551415797,\n      \"min\": 0.9014530551415797,\n      \"avg\": 0.9014530551415797,\n      \"last\": 0.9014530551415797,\n      \"last-5-avg\": 0.9014530551415797,\n      \"last-10-avg\": 0.9014530551415797\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12561.126052856445,\n      \"min\": 12561.126052856445,\n      \"avg\": 12561.126052856445,\n      \"last\": 12561.126052856445,\n      \"last-5-avg\": 12561.126052856445,\n      \"last-10-avg\": 12561.126052856445\n    },\n    \"time_total_s\": {\n      \"max\": 12561.126052856445,\n      \"min\": 12561.126052856445,\n      \"avg\": 12561.126052856445,\n      \"last\": 12561.126052856445,\n      \"last-5-avg\": 12561.126052856445,\n      \"last-10-avg\": 12561.126052856445\n    },\n    \"time_since_restore\": {\n      \"max\": 12561.126052856445,\n      \"min\": 12561.126052856445,\n      \"avg\": 12561.126052856445,\n      \"last\": 12561.126052856445,\n      \"last-5-avg\": 12561.126052856445,\n      \"last-10-avg\": 12561.126052856445\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bbcbd613b4d8ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bbcbd613b4d8ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8889022800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8889022800000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8889022800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8889022800000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8889022800000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8889022800000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00026\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032365f32365f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"26_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00026_26_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716791465.0200598,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8255681818181818,\n    \"timestamp\": 1716801345,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00026\",\n    \"date\": \"2024-05-27_11-15-45\",\n    \"time_this_iter_s\": 4290.780100107193,\n    \"time_total_s\": 9880.511771678925,\n    \"pid\": 336934,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9880.511771678925,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"26_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716801345.5357528,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8255681818181818,\n      \"min\": 0.7736013986013985,\n      \"avg\": 0.7995847902097901,\n      \"last\": 0.8255681818181818,\n      \"last-5-avg\": 0.7995847902097901,\n      \"last-10-avg\": 0.7995847902097901\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5589.731671571732,\n      \"min\": 4290.780100107193,\n      \"avg\": 4940.255885839462,\n      \"last\": 4290.780100107193,\n      \"last-5-avg\": 4940.255885839462,\n      \"last-10-avg\": 4940.255885839462\n    },\n    \"time_total_s\": {\n      \"max\": 9880.511771678925,\n      \"min\": 5589.731671571732,\n      \"avg\": 7735.121721625328,\n      \"last\": 9880.511771678925,\n      \"last-5-avg\": 7735.121721625328,\n      \"last-10-avg\": 7735.121721625328\n    },\n    \"time_since_restore\": {\n      \"max\": 9880.511771678925,\n      \"min\": 5589.731671571732,\n      \"avg\": 7735.121721625328,\n      \"last\": 9880.511771678925,\n      \"last-5-avg\": 7735.121721625328,\n      \"last-10-avg\": 7735.121721625328\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308724064b857c1e83f94869452946807680d43086bdfb0f60d6bea3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308724064b857c1e83f94869452946807680d43086bdfb0f60d6bea3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5d5bb4ed400004740b0c2c7b4a40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5d5bb4ed400004740b0c2c7b4a40000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5d5bb4ed400004740c34c4181bc0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5d5bb4ed400004740c34c4181bc0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5d5bb4ed400004740c34c4181bc0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5d5bb4ed400004740c34c4181bc0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00054\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035345f35345f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"54_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00054_54_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717171786.575825,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8609625668449198,\n    \"timestamp\": 1717183218,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00054\",\n    \"date\": \"2024-05-31_21-20-18\",\n    \"time_this_iter_s\": 3670.616495370865,\n    \"time_total_s\": 11432.175508499146,\n    \"pid\": 493218,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11432.175508499146,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"54_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717183218.7552056,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8609625668449198,\n      \"min\": 0.7982954545454546,\n      \"avg\": 0.8296290106951871,\n      \"last\": 0.8609625668449198,\n      \"last-5-avg\": 0.8296290106951871,\n      \"last-10-avg\": 0.8296290106951871\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7761.559013128281,\n      \"min\": 3670.616495370865,\n      \"avg\": 5716.087754249573,\n      \"last\": 3670.616495370865,\n      \"last-5-avg\": 5716.087754249573,\n      \"last-10-avg\": 5716.087754249573\n    },\n    \"time_total_s\": {\n      \"max\": 11432.175508499146,\n      \"min\": 7761.559013128281,\n      \"avg\": 9596.867260813713,\n      \"last\": 11432.175508499146,\n      \"last-5-avg\": 9596.867260813713,\n      \"last-10-avg\": 9596.867260813713\n    },\n    \"time_since_restore\": {\n      \"max\": 11432.175508499146,\n      \"min\": 7761.559013128281,\n      \"avg\": 9596.867260813713,\n      \"last\": 11432.175508499146,\n      \"last-5-avg\": 9596.867260813713,\n      \"last-10-avg\": 9596.867260813713\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c2ebae8a28be93f94869452946807680d43088dbb755e018deb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088c2ebae8a28be93f94869452946807680d43088dbb755e018deb3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740be518f1b7c00004740acad3ba5480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740be518f1b7c00004740acad3ba5480000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740be518f1b7c00004740c6541677100000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740be518f1b7c00004740c6541677100000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740be518f1b7c00004740c6541677100000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740be518f1b7c00004740c6541677100000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00084\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038345f38345f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"84_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00084_84_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717527510.1746986,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8358745684695051,\n    \"timestamp\": 1717543803,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00084\",\n    \"date\": \"2024-06-05_01-30-03\",\n    \"time_this_iter_s\": 16293.475915431976,\n    \"time_total_s\": 16293.475915431976,\n    \"pid\": 626858,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16293.475915431976,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"84_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717543803.6525025,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8358745684695051,\n      \"min\": 0.8358745684695051,\n      \"avg\": 0.8358745684695051,\n      \"last\": 0.8358745684695051,\n      \"last-5-avg\": 0.8358745684695051,\n      \"last-10-avg\": 0.8358745684695051\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16293.475915431976,\n      \"min\": 16293.475915431976,\n      \"avg\": 16293.475915431976,\n      \"last\": 16293.475915431976,\n      \"last-5-avg\": 16293.475915431976,\n      \"last-10-avg\": 16293.475915431976\n    },\n    \"time_total_s\": {\n      \"max\": 16293.475915431976,\n      \"min\": 16293.475915431976,\n      \"avg\": 16293.475915431976,\n      \"last\": 16293.475915431976,\n      \"last-5-avg\": 16293.475915431976,\n      \"last-10-avg\": 16293.475915431976\n    },\n    \"time_since_restore\": {\n      \"max\": 16293.475915431976,\n      \"min\": 16293.475915431976,\n      \"avg\": 16293.475915431976,\n      \"last\": 16293.475915431976,\n      \"last-5-avg\": 16293.475915431976,\n      \"last-10-avg\": 16293.475915431976\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f34ee4057cbfea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f34ee4057cbfea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfd2bceacc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfd2bceacc0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfd2bceacc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfd2bceacc0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfd2bceacc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfd2bceacc0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00025\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032355f32355f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e313030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"25_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00025_25_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716781407.3631566,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7870553359683793,\n    \"timestamp\": 1716791462,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00025\",\n    \"date\": \"2024-05-27_08-31-02\",\n    \"time_this_iter_s\": 4720.183877468109,\n    \"time_total_s\": 10055.616149425507,\n    \"pid\": 333296,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10055.616149425507,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"25_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716791462.9830759,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7870553359683793,\n      \"min\": 0.6551573426573427,\n      \"avg\": 0.7211063393128609,\n      \"last\": 0.7870553359683793,\n      \"last-5-avg\": 0.7211063393128609,\n      \"last-10-avg\": 0.7211063393128609\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5335.4322719573975,\n      \"min\": 4720.183877468109,\n      \"avg\": 5027.808074712753,\n      \"last\": 4720.183877468109,\n      \"last-5-avg\": 5027.808074712753,\n      \"last-10-avg\": 5027.808074712753\n    },\n    \"time_total_s\": {\n      \"max\": 10055.616149425507,\n      \"min\": 5335.4322719573975,\n      \"avg\": 7695.524210691452,\n      \"last\": 10055.616149425507,\n      \"last-5-avg\": 7695.524210691452,\n      \"last-10-avg\": 7695.524210691452\n    },\n    \"time_since_restore\": {\n      \"max\": 10055.616149425507,\n      \"min\": 5335.4322719573975,\n      \"avg\": 7695.524210691452,\n      \"last\": 10055.616149425507,\n      \"last-5-avg\": 7695.524210691452,\n      \"last-10-avg\": 7695.524210691452\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a520e880cf7e43f94869452946807680d4308230c04ac8e2fe93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a520e880cf7e43f94869452946807680d4308230c04ac8e2fe93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4d76ea96000004740b2702f12980000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4d76ea96000004740b2702f12980000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4d76ea96000004740c3a3ceddfc0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4d76ea96000004740c3a3ceddfc0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4d76ea96000004740c3a3ceddfc0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4d76ea96000004740c3a3ceddfc0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00020\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032305f32305f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3130305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"20_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00020_20_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.100_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716718009.4611197,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8609033371691598,\n    \"timestamp\": 1716734375,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00020\",\n    \"date\": \"2024-05-26_16-39-35\",\n    \"time_this_iter_s\": 16365.574526786804,\n    \"time_total_s\": 16365.574526786804,\n    \"pid\": 309711,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16365.574526786804,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"20_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716734375.0374095,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8609033371691598,\n      \"min\": 0.8609033371691598,\n      \"avg\": 0.8609033371691598,\n      \"last\": 0.8609033371691598,\n      \"last-5-avg\": 0.8609033371691598,\n      \"last-10-avg\": 0.8609033371691598\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16365.574526786804,\n      \"min\": 16365.574526786804,\n      \"avg\": 16365.574526786804,\n      \"last\": 16365.574526786804,\n      \"last-5-avg\": 16365.574526786804,\n      \"last-10-avg\": 16365.574526786804\n    },\n    \"time_total_s\": {\n      \"max\": 16365.574526786804,\n      \"min\": 16365.574526786804,\n      \"avg\": 16365.574526786804,\n      \"last\": 16365.574526786804,\n      \"last-5-avg\": 16365.574526786804,\n      \"last-10-avg\": 16365.574526786804\n    },\n    \"time_since_restore\": {\n      \"max\": 16365.574526786804,\n      \"min\": 16365.574526786804,\n      \"avg\": 16365.574526786804,\n      \"last\": 16365.574526786804,\n      \"last-5-avg\": 16365.574526786804,\n      \"last-10-avg\": 16365.574526786804\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e914c527858ceb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e914c527858ceb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cff6c98a180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cff6c98a180000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cff6c98a180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cff6c98a180000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cff6c98a180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cff6c98a180000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00034\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033345f33345f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"34_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00034_34_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716902218.30924,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8790820829655781,\n    \"timestamp\": 1716924460,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00034\",\n    \"date\": \"2024-05-28_21-27-40\",\n    \"time_this_iter_s\": 22241.91236639023,\n    \"time_total_s\": 22241.91236639023,\n    \"pid\": 379517,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 22241.91236639023,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"34_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716924460.223548,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8790820829655781,\n      \"min\": 0.8790820829655781,\n      \"avg\": 0.8790820829655781,\n      \"last\": 0.8790820829655781,\n      \"last-5-avg\": 0.8790820829655781,\n      \"last-10-avg\": 0.8790820829655781\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 22241.91236639023,\n      \"min\": 22241.91236639023,\n      \"avg\": 22241.91236639023,\n      \"last\": 22241.91236639023,\n      \"last-5-avg\": 22241.91236639023,\n      \"last-10-avg\": 22241.91236639023\n    },\n    \"time_total_s\": {\n      \"max\": 22241.91236639023,\n      \"min\": 22241.91236639023,\n      \"avg\": 22241.91236639023,\n      \"last\": 22241.91236639023,\n      \"last-5-avg\": 22241.91236639023,\n      \"last-10-avg\": 22241.91236639023\n    },\n    \"time_since_restore\": {\n      \"max\": 22241.91236639023,\n      \"min\": 22241.91236639023,\n      \"avg\": 22241.91236639023,\n      \"last\": 22241.91236639023,\n      \"last-5-avg\": 22241.91236639023,\n      \"last-10-avg\": 22241.91236639023\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430862c69abf7021ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430862c69abf7021ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d5b87a64360000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d5b87a64360000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d5b87a64360000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d5b87a64360000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d5b87a64360000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d5b87a64360000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00036\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033365f33365f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"36_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00036_36_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716941162.6770196,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8890648286140088,\n    \"timestamp\": 1716966333,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00036\",\n    \"date\": \"2024-05-29_09-05-33\",\n    \"time_this_iter_s\": 25170.565944433212,\n    \"time_total_s\": 25170.565944433212,\n    \"pid\": 394051,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 25170.565944433212,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"36_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716966333.2447946,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8890648286140088,\n      \"min\": 0.8890648286140088,\n      \"avg\": 0.8890648286140088,\n      \"last\": 0.8890648286140088,\n      \"last-5-avg\": 0.8890648286140088,\n      \"last-10-avg\": 0.8890648286140088\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 25170.565944433212,\n      \"min\": 25170.565944433212,\n      \"avg\": 25170.565944433212,\n      \"last\": 25170.565944433212,\n      \"last-5-avg\": 25170.565944433212,\n      \"last-10-avg\": 25170.565944433212\n    },\n    \"time_total_s\": {\n      \"max\": 25170.565944433212,\n      \"min\": 25170.565944433212,\n      \"avg\": 25170.565944433212,\n      \"last\": 25170.565944433212,\n      \"last-5-avg\": 25170.565944433212,\n      \"last-10-avg\": 25170.565944433212\n    },\n    \"time_since_restore\": {\n      \"max\": 25170.565944433212,\n      \"min\": 25170.565944433212,\n      \"avg\": 25170.565944433212,\n      \"last\": 25170.565944433212,\n      \"last-5-avg\": 25170.565944433212,\n      \"last-10-avg\": 25170.565944433212\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f0785d153873ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f0785d153873ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d894a4386f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d894a4386f0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d894a4386f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d894a4386f0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d894a4386f0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d894a4386f0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00017\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031375f31375f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e313030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"17_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00017_17_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716667626.732215,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8533775252525252,\n    \"timestamp\": 1716682457,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00017\",\n    \"date\": \"2024-05-26_02-14-17\",\n    \"time_this_iter_s\": 14831.095958709717,\n    \"time_total_s\": 14831.095958709717,\n    \"pid\": 290919,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 14831.095958709717,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"17_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716682457.8299928,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8533775252525252,\n      \"min\": 0.8533775252525252,\n      \"avg\": 0.8533775252525252,\n      \"last\": 0.8533775252525252,\n      \"last-5-avg\": 0.8533775252525252,\n      \"last-10-avg\": 0.8533775252525252\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 14831.095958709717,\n      \"min\": 14831.095958709717,\n      \"avg\": 14831.095958709717,\n      \"last\": 14831.095958709717,\n      \"last-5-avg\": 14831.095958709717,\n      \"last-10-avg\": 14831.095958709717\n    },\n    \"time_total_s\": {\n      \"max\": 14831.095958709717,\n      \"min\": 14831.095958709717,\n      \"avg\": 14831.095958709717,\n      \"last\": 14831.095958709717,\n      \"last-5-avg\": 14831.095958709717,\n      \"last-10-avg\": 14831.095958709717\n    },\n    \"time_since_restore\": {\n      \"max\": 14831.095958709717,\n      \"min\": 14831.095958709717,\n      \"avg\": 14831.095958709717,\n      \"last\": 14831.095958709717,\n      \"last-5-avg\": 14831.095958709717,\n      \"last-10-avg\": 14831.095958709717\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308793b4362de4eeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308793b4362de4eeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ccf78c48600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ccf78c48600000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ccf78c48600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ccf78c48600000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ccf78c48600000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ccf78c48600000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00006\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030365f365f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"6_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00006_6_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716550798.8605614,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8664772727272727,\n    \"timestamp\": 1716566292,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00006\",\n    \"date\": \"2024-05-24_17-58-12\",\n    \"time_this_iter_s\": 15493.93283367157,\n    \"time_total_s\": 15493.93283367157,\n    \"pid\": 238313,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15493.93283367157,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"6_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716566292.7950952,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8664772727272727,\n      \"min\": 0.8664772727272727,\n      \"avg\": 0.8664772727272727,\n      \"last\": 0.8664772727272727,\n      \"last-5-avg\": 0.8664772727272727,\n      \"last-10-avg\": 0.8664772727272727\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15493.93283367157,\n      \"min\": 15493.93283367157,\n      \"avg\": 15493.93283367157,\n      \"last\": 15493.93283367157,\n      \"last-5-avg\": 15493.93283367157,\n      \"last-10-avg\": 15493.93283367157\n    },\n    \"time_total_s\": {\n      \"max\": 15493.93283367157,\n      \"min\": 15493.93283367157,\n      \"avg\": 15493.93283367157,\n      \"last\": 15493.93283367157,\n      \"last-5-avg\": 15493.93283367157,\n      \"last-10-avg\": 15493.93283367157\n    },\n    \"time_since_restore\": {\n      \"max\": 15493.93283367157,\n      \"min\": 15493.93283367157,\n      \"avg\": 15493.93283367157,\n      \"last\": 15493.93283367157,\n      \"last-5-avg\": 15493.93283367157,\n      \"last-10-avg\": 15493.93283367157\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2ebaeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2ebaeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce42f767180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce42f767180000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce42f767180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce42f767180000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740ce42f767180000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740ce42f767180000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00086\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038365f38365f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"86_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00086_86_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717559075.0584064,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8339920948616601,\n    \"timestamp\": 1717571096,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00086\",\n    \"date\": \"2024-06-05_09-04-56\",\n    \"time_this_iter_s\": 4933.313364744186,\n    \"time_total_s\": 12021.323989629745,\n    \"pid\": 639017,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 12021.323989629745,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"86_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717571096.3862402,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8339920948616601,\n      \"min\": 0.7665289256198348,\n      \"avg\": 0.8002605102407474,\n      \"last\": 0.8339920948616601,\n      \"last-5-avg\": 0.8002605102407474,\n      \"last-10-avg\": 0.8002605102407474\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7088.010624885559,\n      \"min\": 4933.313364744186,\n      \"avg\": 6010.661994814873,\n      \"last\": 4933.313364744186,\n      \"last-5-avg\": 6010.661994814873,\n      \"last-10-avg\": 6010.661994814873\n    },\n    \"time_total_s\": {\n      \"max\": 12021.323989629745,\n      \"min\": 7088.010624885559,\n      \"avg\": 9554.667307257652,\n      \"last\": 12021.323989629745,\n      \"last-5-avg\": 9554.667307257652,\n      \"last-10-avg\": 9554.667307257652\n    },\n    \"time_since_restore\": {\n      \"max\": 12021.323989629745,\n      \"min\": 7088.010624885559,\n      \"avg\": 9554.667307257652,\n      \"last\": 12021.323989629745,\n      \"last-5-avg\": 9554.667307257652,\n      \"last-10-avg\": 9554.667307257652\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e5345fab6787e83f94869452946807680d430820b5913010b0ea3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e5345fab6787e83f94869452946807680d430820b5913010b0ea3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bbb002b85000004740b3455038ac0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bbb002b85000004740b3455038ac0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bbb002b85000004740c77aa9787e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bbb002b85000004740c77aa9787e0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740bbb002b85000004740c77aa9787e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740bbb002b85000004740c77aa9787e0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00087\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038375f38375f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"87_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00087_87_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717571098.9242234,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9078947368421054,\n    \"timestamp\": 1717587888,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00087\",\n    \"date\": \"2024-06-05_13-44-48\",\n    \"time_this_iter_s\": 4087.051549434662,\n    \"time_total_s\": 16789.163320541382,\n    \"pid\": 644077,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16789.163320541382,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"87_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717587888.091232,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9078947368421054,\n      \"min\": 0.7921802773497687,\n      \"avg\": 0.8500375070959371,\n      \"last\": 0.9078947368421054,\n      \"last-5-avg\": 0.8500375070959371,\n      \"last-10-avg\": 0.8500375070959371\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12702.11177110672,\n      \"min\": 4087.051549434662,\n      \"avg\": 8394.581660270691,\n      \"last\": 4087.051549434662,\n      \"last-5-avg\": 8394.581660270691,\n      \"last-10-avg\": 8394.581660270691\n    },\n    \"time_total_s\": {\n      \"max\": 16789.163320541382,\n      \"min\": 12702.11177110672,\n      \"avg\": 14745.63754582405,\n      \"last\": 16789.163320541382,\n      \"last-5-avg\": 14745.63754582405,\n      \"last-10-avg\": 14745.63754582405\n    },\n    \"time_since_restore\": {\n      \"max\": 16789.163320541382,\n      \"min\": 12702.11177110672,\n      \"avg\": 14745.63754582405,\n      \"last\": 16789.163320541382,\n      \"last-5-avg\": 14745.63754582405,\n      \"last-10-avg\": 14745.63754582405\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308651cf8738a59e93f94869452946807680d4308d9505e43790ded3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308651cf8738a59e93f94869452946807680d4308d9505e43790ded3f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8cf0e4e8400004740afee1a64b00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8cf0e4e8400004740afee1a64b00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8cf0e4e8400004740d0654a73d80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8cf0e4e8400004740d0654a73d80000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c8cf0e4e8400004740d0654a73d80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c8cf0e4e8400004740d0654a73d80000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00058\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035385f35385f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"58_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00058_58_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717216747.4751425,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7926136363636365,\n    \"timestamp\": 1717225799,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00058\",\n    \"date\": \"2024-06-01_09-09-59\",\n    \"time_this_iter_s\": 3448.978838443756,\n    \"time_total_s\": 9051.823023557663,\n    \"pid\": 509979,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9051.823023557663,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"58_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717225799.3021288,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7926136363636365,\n      \"min\": 0.7019230769230769,\n      \"avg\": 0.7472683566433567,\n      \"last\": 0.7926136363636365,\n      \"last-5-avg\": 0.7472683566433567,\n      \"last-10-avg\": 0.7472683566433567\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5602.844185113907,\n      \"min\": 3448.978838443756,\n      \"avg\": 4525.9115117788315,\n      \"last\": 3448.978838443756,\n      \"last-5-avg\": 4525.9115117788315,\n      \"last-10-avg\": 4525.9115117788315\n    },\n    \"time_total_s\": {\n      \"max\": 9051.823023557663,\n      \"min\": 5602.844185113907,\n      \"avg\": 7327.333604335785,\n      \"last\": 9051.823023557663,\n      \"last-5-avg\": 7327.333604335785,\n      \"last-10-avg\": 7327.333604335785\n    },\n    \"time_since_restore\": {\n      \"max\": 9051.823023557663,\n      \"min\": 5602.844185113907,\n      \"avg\": 7327.333604335785,\n      \"last\": 9051.823023557663,\n      \"last-5-avg\": 7327.333604335785,\n      \"last-10-avg\": 7327.333604335785\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622776622776e63f94869452946807680d43085e74d145175de93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308622776622776e63f94869452946807680d43085e74d145175de93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5e2d81c8400004740aaf1f52a500000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5e2d81c8400004740aaf1f52a500000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5e2d81c8400004740c1ade958d60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5e2d81c8400004740c1ade958d60000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b5e2d81c8400004740c1ade958d60000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b5e2d81c8400004740c1ade958d60000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00035\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033355f33355f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"35_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00035_35_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716924462.9455264,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9039256198347106,\n    \"timestamp\": 1716941160,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00035\",\n    \"date\": \"2024-05-29_02-06-00\",\n    \"time_this_iter_s\": 16697.701008081436,\n    \"time_total_s\": 16697.701008081436,\n    \"pid\": 387957,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16697.701008081436,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"35_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716941160.6485176,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9039256198347106,\n      \"min\": 0.9039256198347106,\n      \"avg\": 0.9039256198347106,\n      \"last\": 0.9039256198347106,\n      \"last-5-avg\": 0.9039256198347106,\n      \"last-10-avg\": 0.9039256198347106\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16697.701008081436,\n      \"min\": 16697.701008081436,\n      \"avg\": 16697.701008081436,\n      \"last\": 16697.701008081436,\n      \"last-5-avg\": 16697.701008081436,\n      \"last-10-avg\": 16697.701008081436\n    },\n    \"time_total_s\": {\n      \"max\": 16697.701008081436,\n      \"min\": 16697.701008081436,\n      \"avg\": 16697.701008081436,\n      \"last\": 16697.701008081436,\n      \"last-5-avg\": 16697.701008081436,\n      \"last-10-avg\": 16697.701008081436\n    },\n    \"time_since_restore\": {\n      \"max\": 16697.701008081436,\n      \"min\": 16697.701008081436,\n      \"avg\": 16697.701008081436,\n      \"last\": 16697.701008081436,\n      \"last-5-avg\": 16697.701008081436,\n      \"last-10-avg\": 16697.701008081436\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088f9ce66bf5ecec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088f9ce66bf5ecec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d04e6cdd510000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d04e6cdd510000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d04e6cdd510000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d04e6cdd510000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740d04e6cdd510000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740d04e6cdd510000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00071\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037315f37315f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"71_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00071_71_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717402985.137112,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9004186602870812,\n    \"timestamp\": 1717411222,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00071\",\n    \"date\": \"2024-06-03_12-40-22\",\n    \"time_this_iter_s\": 8237.629189491272,\n    \"time_total_s\": 8237.629189491272,\n    \"pid\": 579523,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8237.629189491272,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"71_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717411222.768334,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9004186602870812,\n      \"min\": 0.9004186602870812,\n      \"avg\": 0.9004186602870812,\n      \"last\": 0.9004186602870812,\n      \"last-5-avg\": 0.9004186602870812,\n      \"last-10-avg\": 0.9004186602870812\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8237.629189491272,\n      \"min\": 8237.629189491272,\n      \"avg\": 8237.629189491272,\n      \"last\": 8237.629189491272,\n      \"last-5-avg\": 8237.629189491272,\n      \"last-10-avg\": 8237.629189491272\n    },\n    \"time_total_s\": {\n      \"max\": 8237.629189491272,\n      \"min\": 8237.629189491272,\n      \"avg\": 8237.629189491272,\n      \"last\": 8237.629189491272,\n      \"last-5-avg\": 8237.629189491272,\n      \"last-10-avg\": 8237.629189491272\n    },\n    \"time_since_restore\": {\n      \"max\": 8237.629189491272,\n      \"min\": 8237.629189491272,\n      \"avg\": 8237.629189491272,\n      \"last\": 8237.629189491272,\n      \"last-5-avg\": 8237.629189491272,\n      \"last-10-avg\": 8237.629189491272\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308488454cb3ad0ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308488454cb3ad0ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c016d089480000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c016d089480000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c016d089480000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c016d089480000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c016d089480000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c016d089480000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00005\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030355f355f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"5_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00005_5_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716542342.296851,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8678977272727273,\n    \"timestamp\": 1716550796,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00005\",\n    \"date\": \"2024-05-24_13-39-56\",\n    \"time_this_iter_s\": 8454.471444368362,\n    \"time_total_s\": 8454.471444368362,\n    \"pid\": 233954,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8454.471444368362,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"5_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716550796.770224,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8678977272727273,\n      \"min\": 0.8678977272727273,\n      \"avg\": 0.8678977272727273,\n      \"last\": 0.8678977272727273,\n      \"last-5-avg\": 0.8678977272727273,\n      \"last-10-avg\": 0.8678977272727273\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8454.471444368362,\n      \"min\": 8454.471444368362,\n      \"avg\": 8454.471444368362,\n      \"last\": 8454.471444368362,\n      \"last-5-avg\": 8454.471444368362,\n      \"last-10-avg\": 8454.471444368362\n    },\n    \"time_total_s\": {\n      \"max\": 8454.471444368362,\n      \"min\": 8454.471444368362,\n      \"avg\": 8454.471444368362,\n      \"last\": 8454.471444368362,\n      \"last-5-avg\": 8454.471444368362,\n      \"last-10-avg\": 8454.471444368362\n    },\n    \"time_since_restore\": {\n      \"max\": 8454.471444368362,\n      \"min\": 8454.471444368362,\n      \"avg\": 8454.471444368362,\n      \"last\": 8454.471444368362,\n      \"last-5-avg\": 8454.471444368362,\n      \"last-10-avg\": 8454.471444368362\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430846175d74d1c5eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430846175d74d1c5eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0833c584a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0833c584a0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0833c584a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0833c584a0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c0833c584a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c0833c584a0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00014\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303031345f31345f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e31305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"14_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00014_14_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.10_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716634516.878751,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8367768595041323,\n    \"timestamp\": 1716641621,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00014\",\n    \"date\": \"2024-05-25_14-53-41\",\n    \"time_this_iter_s\": 7105.074226140976,\n    \"time_total_s\": 7105.074226140976,\n    \"pid\": 277964,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 7105.074226140976,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"14_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716641621.9548295,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8367768595041323,\n      \"min\": 0.8367768595041323,\n      \"avg\": 0.8367768595041323,\n      \"last\": 0.8367768595041323,\n      \"last-5-avg\": 0.8367768595041323,\n      \"last-10-avg\": 0.8367768595041323\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7105.074226140976,\n      \"min\": 7105.074226140976,\n      \"avg\": 7105.074226140976,\n      \"last\": 7105.074226140976,\n      \"last-5-avg\": 7105.074226140976,\n      \"last-10-avg\": 7105.074226140976\n    },\n    \"time_total_s\": {\n      \"max\": 7105.074226140976,\n      \"min\": 7105.074226140976,\n      \"avg\": 7105.074226140976,\n      \"last\": 7105.074226140976,\n      \"last-5-avg\": 7105.074226140976,\n      \"last-10-avg\": 7105.074226140976\n    },\n    \"time_since_restore\": {\n      \"max\": 7105.074226140976,\n      \"min\": 7105.074226140976,\n      \"avg\": 7105.074226140976,\n      \"last\": 7105.074226140976,\n      \"last-5-avg\": 7105.074226140976,\n      \"last-10-avg\": 7105.074226140976\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b0d5b343e0c6ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b0d5b343e0c6ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbc113007c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbc113007c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbc113007c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbc113007c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bbc113007c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bbc113007c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00059\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035395f35395f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"59_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00059_59_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717225801.9047272,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8075284090909092,\n    \"timestamp\": 1717235267,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00059\",\n    \"date\": \"2024-06-01_11-47-47\",\n    \"time_this_iter_s\": 3439.6838505268097,\n    \"time_total_s\": 9465.848240375519,\n    \"pid\": 513774,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9465.848240375519,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"59_alpha=0.8500,feature_maps=128_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717235267.756926,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8075284090909092,\n      \"min\": 0.7723214285714287,\n      \"avg\": 0.789924918831169,\n      \"last\": 0.8075284090909092,\n      \"last-5-avg\": 0.789924918831169,\n      \"last-10-avg\": 0.789924918831169\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6026.164389848709,\n      \"min\": 3439.6838505268097,\n      \"avg\": 4732.924120187759,\n      \"last\": 3439.6838505268097,\n      \"last-5-avg\": 4732.924120187759,\n      \"last-10-avg\": 4732.924120187759\n    },\n    \"time_total_s\": {\n      \"max\": 9465.848240375519,\n      \"min\": 6026.164389848709,\n      \"avg\": 7746.006315112114,\n      \"last\": 9465.848240375519,\n      \"last-5-avg\": 7746.006315112114,\n      \"last-10-avg\": 7746.006315112114\n    },\n    \"time_since_restore\": {\n      \"max\": 9465.848240375519,\n      \"min\": 6026.164389848709,\n      \"avg\": 7746.006315112114,\n      \"last\": 9465.848240375519,\n      \"last-5-avg\": 7746.006315112114,\n      \"last-10-avg\": 7746.006315112114\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086fdbb66ddbb6e83f94869452946807680d4308185d74d145d7e93f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086fdbb66ddbb6e83f94869452946807680d4308185d74d145d7e93f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b78a2a157400004740aadf5e21a80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b78a2a157400004740aadf5e21a80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b78a2a157400004740c27cec93240000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b78a2a157400004740c27cec93240000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b78a2a157400004740c27cec93240000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b78a2a157400004740c27cec93240000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00046\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034365f34365f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"46_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00046_46_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717067368.5451038,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8469460227272727,\n    \"timestamp\": 1717074434,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00046\",\n    \"date\": \"2024-05-30_15-07-14\",\n    \"time_this_iter_s\": 7066.107871770859,\n    \"time_total_s\": 7066.107871770859,\n    \"pid\": 453316,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 7066.107871770859,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"46_alpha=0.9900,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717074434.6550894,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8469460227272727,\n      \"min\": 0.8469460227272727,\n      \"avg\": 0.8469460227272727,\n      \"last\": 0.8469460227272727,\n      \"last-5-avg\": 0.8469460227272727,\n      \"last-10-avg\": 0.8469460227272727\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 7066.107871770859,\n      \"min\": 7066.107871770859,\n      \"avg\": 7066.107871770859,\n      \"last\": 7066.107871770859,\n      \"last-5-avg\": 7066.107871770859,\n      \"last-10-avg\": 7066.107871770859\n    },\n    \"time_total_s\": {\n      \"max\": 7066.107871770859,\n      \"min\": 7066.107871770859,\n      \"avg\": 7066.107871770859,\n      \"last\": 7066.107871770859,\n      \"last-5-avg\": 7066.107871770859,\n      \"last-10-avg\": 7066.107871770859\n    },\n    \"time_since_restore\": {\n      \"max\": 7066.107871770859,\n      \"min\": 7066.107871770859,\n      \"avg\": 7066.107871770859,\n      \"last\": 7066.107871770859,\n      \"last-5-avg\": 7066.107871770859,\n      \"last-10-avg\": 7066.107871770859\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2e1aeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308bae8a28b2e1aeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb9a1b9d7c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb9a1b9d7c0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb9a1b9d7c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb9a1b9d7c0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740bb9a1b9d7c0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740bb9a1b9d7c0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00063\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036335f36335f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e35305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"63_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00063_63_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.50_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717269265.5725358,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.712603305785124,\n    \"timestamp\": 1717287195,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00063\",\n    \"date\": \"2024-06-02_02-13-15\",\n    \"time_this_iter_s\": 11882.433979034424,\n    \"time_total_s\": 17929.94293165207,\n    \"pid\": 529853,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 17929.94293165207,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"63_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717287195.5191875,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.712603305785124,\n      \"min\": 0.6737012987012986,\n      \"avg\": 0.6931523022432113,\n      \"last\": 0.712603305785124,\n      \"last-5-avg\": 0.6931523022432113,\n      \"last-10-avg\": 0.6931523022432113\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11882.433979034424,\n      \"min\": 6047.508952617645,\n      \"avg\": 8964.971465826035,\n      \"last\": 11882.433979034424,\n      \"last-5-avg\": 8964.971465826035,\n      \"last-10-avg\": 8964.971465826035\n    },\n    \"time_total_s\": {\n      \"max\": 17929.94293165207,\n      \"min\": 6047.508952617645,\n      \"avg\": 11988.725942134857,\n      \"last\": 17929.94293165207,\n      \"last-5-avg\": 11988.725942134857,\n      \"last-10-avg\": 11988.725942134857\n    },\n    \"time_since_restore\": {\n      \"max\": 17929.94293165207,\n      \"min\": 6047.508952617645,\n      \"avg\": 11988.725942134857,\n      \"last\": 17929.94293165207,\n      \"last-5-avg\": 11988.725942134857,\n      \"last-10-avg\": 11988.725942134857\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d73ba606f68ee53f94869452946807680d430888cbab72a5cde63f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d73ba606f68ee53f94869452946807680d430888cbab72a5cde63f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b79f824ab800004740c735378ca00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b79f824ab800004740c735378ca00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b79f824ab800004740d1827c58fe0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b79f824ab800004740d1827c58fe0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b79f824ab800004740d1827c58fe0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b79f824ab800004740d1827c58fe0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00073\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037335f37335f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"73_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00073_73_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717417646.359618,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9023845007451565,\n    \"timestamp\": 1717430307,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00073\",\n    \"date\": \"2024-06-03_17-58-27\",\n    \"time_this_iter_s\": 12661.023391008377,\n    \"time_total_s\": 12661.023391008377,\n    \"pid\": 584952,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 12661.023391008377,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"73_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717430307.3848035,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9023845007451565,\n      \"min\": 0.9023845007451565,\n      \"avg\": 0.9023845007451565,\n      \"last\": 0.9023845007451565,\n      \"last-5-avg\": 0.9023845007451565,\n      \"last-10-avg\": 0.9023845007451565\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12661.023391008377,\n      \"min\": 12661.023391008377,\n      \"avg\": 12661.023391008377,\n      \"last\": 12661.023391008377,\n      \"last-5-avg\": 12661.023391008377,\n      \"last-10-avg\": 12661.023391008377\n    },\n    \"time_total_s\": {\n      \"max\": 12661.023391008377,\n      \"min\": 12661.023391008377,\n      \"avg\": 12661.023391008377,\n      \"last\": 12661.023391008377,\n      \"last-5-avg\": 12661.023391008377,\n      \"last-10-avg\": 12661.023391008377\n    },\n    \"time_since_restore\": {\n      \"max\": 12661.023391008377,\n      \"min\": 12661.023391008377,\n      \"avg\": 12661.023391008377,\n      \"last\": 12661.023391008377,\n      \"last-5-avg\": 12661.023391008377,\n      \"last-10-avg\": 12661.023391008377\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087cc4e37555e0ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087cc4e37555e0ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8ba82fe7a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8ba82fe7a0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8ba82fe7a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8ba82fe7a0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c8ba82fe7a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c8ba82fe7a0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00009\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059535030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c956f626a6563746976655f35623364665f30303030395f395f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"9_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00009_9_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716578530.777781,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8997933884297519,\n    \"timestamp\": 1716594409,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00009\",\n    \"date\": \"2024-05-25_01-46-49\",\n    \"time_this_iter_s\": 15878.598729133606,\n    \"time_total_s\": 15878.598729133606,\n    \"pid\": 257169,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 15878.598729133606,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"9_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716594409.3784013,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8997933884297519,\n      \"min\": 0.8997933884297519,\n      \"avg\": 0.8997933884297519,\n      \"last\": 0.8997933884297519,\n      \"last-5-avg\": 0.8997933884297519,\n      \"last-10-avg\": 0.8997933884297519\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 15878.598729133606,\n      \"min\": 15878.598729133606,\n      \"avg\": 15878.598729133606,\n      \"last\": 15878.598729133606,\n      \"last-5-avg\": 15878.598729133606,\n      \"last-10-avg\": 15878.598729133606\n    },\n    \"time_total_s\": {\n      \"max\": 15878.598729133606,\n      \"min\": 15878.598729133606,\n      \"avg\": 15878.598729133606,\n      \"last\": 15878.598729133606,\n      \"last-5-avg\": 15878.598729133606,\n      \"last-10-avg\": 15878.598729133606\n    },\n    \"time_since_restore\": {\n      \"max\": 15878.598729133606,\n      \"min\": 15878.598729133606,\n      \"avg\": 15878.598729133606,\n      \"last\": 15878.598729133606,\n      \"last-5-avg\": 15878.598729133606,\n      \"last-10-avg\": 15878.598729133606\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430855cf0e811bcbec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430855cf0e811bcbec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cf034ca3280000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cf034ca3280000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cf034ca3280000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cf034ca3280000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cf034ca3280000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cf034ca3280000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00007\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303030375f375f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3130305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"7_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00007_7_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.100_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716566294.586509,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8383264462809918,\n    \"timestamp\": 1716571103,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00007\",\n    \"date\": \"2024-05-24_19-18-23\",\n    \"time_this_iter_s\": 4809.193681716919,\n    \"time_total_s\": 4809.193681716919,\n    \"pid\": 252610,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 4809.193681716919,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"7_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716571103.782044,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8383264462809918,\n      \"min\": 0.8383264462809918,\n      \"avg\": 0.8383264462809918,\n      \"last\": 0.8383264462809918,\n      \"last-5-avg\": 0.8383264462809918,\n      \"last-10-avg\": 0.8383264462809918\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 4809.193681716919,\n      \"min\": 4809.193681716919,\n      \"avg\": 4809.193681716919,\n      \"last\": 4809.193681716919,\n      \"last-5-avg\": 4809.193681716919,\n      \"last-10-avg\": 4809.193681716919\n    },\n    \"time_total_s\": {\n      \"max\": 4809.193681716919,\n      \"min\": 4809.193681716919,\n      \"avg\": 4809.193681716919,\n      \"last\": 4809.193681716919,\n      \"last-5-avg\": 4809.193681716919,\n      \"last-10-avg\": 4809.193681716919\n    },\n    \"time_since_restore\": {\n      \"max\": 4809.193681716919,\n      \"min\": 4809.193681716919,\n      \"avg\": 4809.193681716919,\n      \"last\": 4809.193681716919,\n      \"last-5-avg\": 4809.193681716919,\n      \"last-10-avg\": 4809.193681716919\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6c2c4fb91d3ea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a6c2c4fb91d3ea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b2c93195200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b2c93195200000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b2c93195200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b2c93195200000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b2c93195200000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b2c93195200000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00072\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037325f37325f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"72_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00072_72_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717411225.4105697,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8497067448680352,\n    \"timestamp\": 1717417644,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00072\",\n    \"date\": \"2024-06-03_14-27-24\",\n    \"time_this_iter_s\": 6419.072537183762,\n    \"time_total_s\": 6419.072537183762,\n    \"pid\": 582577,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 6419.072537183762,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"72_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717417644.485084,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8497067448680352,\n      \"min\": 0.8497067448680352,\n      \"avg\": 0.8497067448680352,\n      \"last\": 0.8497067448680352,\n      \"last-5-avg\": 0.8497067448680352,\n      \"last-10-avg\": 0.8497067448680352\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6419.072537183762,\n      \"min\": 6419.072537183762,\n      \"avg\": 6419.072537183762,\n      \"last\": 6419.072537183762,\n      \"last-5-avg\": 6419.072537183762,\n      \"last-10-avg\": 6419.072537183762\n    },\n    \"time_total_s\": {\n      \"max\": 6419.072537183762,\n      \"min\": 6419.072537183762,\n      \"avg\": 6419.072537183762,\n      \"last\": 6419.072537183762,\n      \"last-5-avg\": 6419.072537183762,\n      \"last-10-avg\": 6419.072537183762\n    },\n    \"time_since_restore\": {\n      \"max\": 6419.072537183762,\n      \"min\": 6419.072537183762,\n      \"avg\": 6419.072537183762,\n      \"last\": 6419.072537183762,\n      \"last-5-avg\": 6419.072537183762,\n      \"last-10-avg\": 6419.072537183762\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430831c30c33cc30eb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430831c30c33cc30eb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b9131291cc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b9131291cc0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b9131291cc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b9131291cc0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b9131291cc0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b9131291cc0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00061\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303036315f36315f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"61_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00061_61_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717243709.6471124,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.6870629370629371,\n    \"timestamp\": 1717255363,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00061\",\n    \"date\": \"2024-06-01_17-22-43\",\n    \"time_this_iter_s\": 5407.779626607895,\n    \"time_total_s\": 11653.656980514526,\n    \"pid\": 520299,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11653.656980514526,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"61_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717255363.308107,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6870629370629371,\n      \"min\": 0.6246212121212122,\n      \"avg\": 0.6558420745920747,\n      \"last\": 0.6870629370629371,\n      \"last-5-avg\": 0.6558420745920747,\n      \"last-10-avg\": 0.6558420745920747\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6245.8773539066315,\n      \"min\": 5407.779626607895,\n      \"avg\": 5826.828490257263,\n      \"last\": 5407.779626607895,\n      \"last-5-avg\": 5826.828490257263,\n      \"last-10-avg\": 5826.828490257263\n    },\n    \"time_total_s\": {\n      \"max\": 11653.656980514526,\n      \"min\": 6245.8773539066315,\n      \"avg\": 8949.767167210579,\n      \"last\": 11653.656980514526,\n      \"last-5-avg\": 8949.767167210579,\n      \"last-10-avg\": 8949.767167210579\n    },\n    \"time_since_restore\": {\n      \"max\": 11653.656980514526,\n      \"min\": 6245.8773539066315,\n      \"avg\": 8949.767167210579,\n      \"last\": 11653.656980514526,\n      \"last-5-avg\": 8949.767167210579,\n      \"last-10-avg\": 8949.767167210579\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fe59ce9fe5fce33f94869452946807680d430824549f696bfce53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fe59ce9fe5fce33f94869452946807680d430824549f696bfce53f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b865e09a4400004740b51fc7959c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b865e09a4400004740b51fc7959c0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b865e09a4400004740c6c2d417f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b865e09a4400004740c6c2d417f00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b865e09a4400004740c6c2d417f00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b865e09a4400004740c6c2d417f00000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00024\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303032345f32345f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e313030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"24_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00024_24_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716772529.8503244,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.6363636363636365,\n    \"timestamp\": 1716781404,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00024\",\n    \"date\": \"2024-05-27_05-43-24\",\n    \"time_this_iter_s\": 3504.109454870224,\n    \"time_total_s\": 8875.04474067688,\n    \"pid\": 330186,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8875.04474067688,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"24_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716781404.8989031,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6381118881118881,\n      \"min\": 0.6363636363636365,\n      \"avg\": 0.6372377622377623,\n      \"last\": 0.6363636363636365,\n      \"last-5-avg\": 0.6372377622377623,\n      \"last-10-avg\": 0.6372377622377623\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5370.935285806656,\n      \"min\": 3504.109454870224,\n      \"avg\": 4437.52237033844,\n      \"last\": 3504.109454870224,\n      \"last-5-avg\": 4437.52237033844,\n      \"last-10-avg\": 4437.52237033844\n    },\n    \"time_total_s\": {\n      \"max\": 8875.04474067688,\n      \"min\": 5370.935285806656,\n      \"avg\": 7122.990013241768,\n      \"last\": 8875.04474067688,\n      \"last-5-avg\": 7122.990013241768,\n      \"last-10-avg\": 7122.990013241768\n    },\n    \"time_since_restore\": {\n      \"max\": 8875.04474067688,\n      \"min\": 5370.935285806656,\n      \"avg\": 7122.990013241768,\n      \"last\": 8875.04474067688,\n      \"last-5-avg\": 7122.990013241768,\n      \"last-10-avg\": 7122.990013241768\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce23549f696be43f94869452946807680d43085e74d145175de43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ce23549f696be43f94869452946807680d43085e74d145175de43f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4faef6ee400004740ab60380a780000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4faef6ee400004740ab60380a780000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4faef6ee400004740c15585ba100000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4faef6ee400004740c15585ba100000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4faef6ee400004740c15585ba100000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4faef6ee400004740c15585ba100000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00045\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303034355f34355f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"45_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00045_45_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717055446.6882133,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8912337662337662,\n    \"timestamp\": 1717067366,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00045\",\n    \"date\": \"2024-05-30_13-09-26\",\n    \"time_this_iter_s\": 11919.556218385696,\n    \"time_total_s\": 11919.556218385696,\n    \"pid\": 448711,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11919.556218385696,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"45_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1717067366.2466042,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8912337662337662,\n      \"min\": 0.8912337662337662,\n      \"avg\": 0.8912337662337662,\n      \"last\": 0.8912337662337662,\n      \"last-5-avg\": 0.8912337662337662,\n      \"last-10-avg\": 0.8912337662337662\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 11919.556218385696,\n      \"min\": 11919.556218385696,\n      \"avg\": 11919.556218385696,\n      \"last\": 11919.556218385696,\n      \"last-5-avg\": 11919.556218385696,\n      \"last-10-avg\": 11919.556218385696\n    },\n    \"time_total_s\": {\n      \"max\": 11919.556218385696,\n      \"min\": 11919.556218385696,\n      \"avg\": 11919.556218385696,\n      \"last\": 11919.556218385696,\n      \"last-5-avg\": 11919.556218385696,\n      \"last-10-avg\": 11919.556218385696\n    },\n    \"time_since_restore\": {\n      \"max\": 11919.556218385696,\n      \"min\": 11919.556218385696,\n      \"avg\": 11919.556218385696,\n      \"last\": 11919.556218385696,\n      \"last-5-avg\": 11919.556218385696,\n      \"last-10-avg\": 11919.556218385696\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f213e2acfc84ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f213e2acfc84ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c747c7322a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c747c7322a0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c747c7322a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c747c7322a0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c747c7322a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c747c7322a0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00031\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033315f33315f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e31305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"31_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00031_31_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.10_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716848891.6299806,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.6837121212121212,\n    \"timestamp\": 1716859444,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00031\",\n    \"date\": \"2024-05-28_03-24-04\",\n    \"time_this_iter_s\": 5162.151212692261,\n    \"time_total_s\": 10553.124024391174,\n    \"pid\": 359129,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10553.124024391174,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"31_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.1000\"\n  },\n  \"last_result_time\": 1716859444.757888,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6837121212121212,\n      \"min\": 0.668181818181818,\n      \"avg\": 0.6759469696969695,\n      \"last\": 0.6837121212121212,\n      \"last-5-avg\": 0.6759469696969695,\n      \"last-10-avg\": 0.6759469696969695\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5390.972811698914,\n      \"min\": 5162.151212692261,\n      \"avg\": 5276.562012195587,\n      \"last\": 5162.151212692261,\n      \"last-5-avg\": 5276.562012195587,\n      \"last-10-avg\": 5276.562012195587\n    },\n    \"time_total_s\": {\n      \"max\": 10553.124024391174,\n      \"min\": 5390.972811698914,\n      \"avg\": 7972.048418045044,\n      \"last\": 10553.124024391174,\n      \"last-5-avg\": 7972.048418045044,\n      \"last-10-avg\": 7972.048418045044\n    },\n    \"time_since_restore\": {\n      \"max\": 10553.124024391174,\n      \"min\": 5390.972811698914,\n      \"avg\": 7972.048418045044,\n      \"last\": 10553.124024391174,\n      \"last-5-avg\": 7972.048418045044,\n      \"last-10-avg\": 7972.048418045044\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430860ed1bd6be61e53f94869452946807680d4308e1830f3ef8e0e53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430860ed1bd6be61e53f94869452946807680d4308e1830f3ef8e0e53f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b50ef90a3000004740b42a26b5e00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b50ef90a3000004740b42a26b5e00000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b50ef90a3000004740c49c8fe0080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b50ef90a3000004740c49c8fe0080000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b50ef90a3000004740c49c8fe0080000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b50ef90a3000004740c49c8fe0080000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00001\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059535030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c956f626a6563746976655f35623364665f30303030315f315f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.85,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"1_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00001_1_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716480106.0922942,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.9006410256410258,\n    \"timestamp\": 1716496414,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00001\",\n    \"date\": \"2024-05-23_22-33-34\",\n    \"time_this_iter_s\": 16308.481216192245,\n    \"time_total_s\": 16308.481216192245,\n    \"pid\": 204022,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.85,\n      \"tau\": 0.1,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 16308.481216192245,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"1_alpha=0.8500,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\"\n  },\n  \"last_result_time\": 1716496414.5752535,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.9006410256410258,\n      \"min\": 0.9006410256410258,\n      \"avg\": 0.9006410256410258,\n      \"last\": 0.9006410256410258,\n      \"last-5-avg\": 0.9006410256410258,\n      \"last-10-avg\": 0.9006410256410258\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 16308.481216192245,\n      \"min\": 16308.481216192245,\n      \"avg\": 16308.481216192245,\n      \"last\": 16308.481216192245,\n      \"last-5-avg\": 16308.481216192245,\n      \"last-10-avg\": 16308.481216192245\n    },\n    \"time_total_s\": {\n      \"max\": 16308.481216192245,\n      \"min\": 16308.481216192245,\n      \"avg\": 16308.481216192245,\n      \"last\": 16308.481216192245,\n      \"last-5-avg\": 16308.481216192245,\n      \"last-10-avg\": 16308.481216192245\n    },\n    \"time_since_restore\": {\n      \"max\": 16308.481216192245,\n      \"min\": 16308.481216192245,\n      \"avg\": 16308.481216192245,\n      \"last\": 16308.481216192245,\n      \"last-5-avg\": 16308.481216192245,\n      \"last-10-avg\": 16308.481216192245\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308220dd2200dd2ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308220dd2200dd2ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfda3d987e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfda3d987e0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfda3d987e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfda3d987e0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cfda3d987e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cfda3d987e0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00032\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303033325f33325f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"32_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00032_32_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716859447.368903,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8877306903622693,\n    \"timestamp\": 1716886911,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00032\",\n    \"date\": \"2024-05-28_11-01-51\",\n    \"time_this_iter_s\": 27463.653807401657,\n    \"time_total_s\": 27463.653807401657,\n    \"pid\": 363407,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 27463.653807401657,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"32_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.5000\"\n  },\n  \"last_result_time\": 1716886911.0245514,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8877306903622693,\n      \"min\": 0.8877306903622693,\n      \"avg\": 0.8877306903622693,\n      \"last\": 0.8877306903622693,\n      \"last-5-avg\": 0.8877306903622693,\n      \"last-10-avg\": 0.8877306903622693\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 27463.653807401657,\n      \"min\": 27463.653807401657,\n      \"avg\": 27463.653807401657,\n      \"last\": 27463.653807401657,\n      \"last-5-avg\": 27463.653807401657,\n      \"last-10-avg\": 27463.653807401657\n    },\n    \"time_total_s\": {\n      \"max\": 27463.653807401657,\n      \"min\": 27463.653807401657,\n      \"avg\": 27463.653807401657,\n      \"last\": 27463.653807401657,\n      \"last-5-avg\": 27463.653807401657,\n      \"last-10-avg\": 27463.653807401657\n    },\n    \"time_since_restore\": {\n      \"max\": 27463.653807401657,\n      \"min\": 27463.653807401657,\n      \"avg\": 27463.653807401657,\n      \"last\": 27463.653807401657,\n      \"last-5-avg\": 27463.653807401657,\n      \"last-10-avg\": 27463.653807401657\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ca5d58314a68ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ca5d58314a68ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740dad1e9d7fb0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740dad1e9d7fb0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740dad1e9d7fb0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740dad1e9d7fb0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740dad1e9d7fb0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740dad1e9d7fb0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00079\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037395f37395f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"79_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00079_79_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717469850.5087576,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8994905956112852,\n    \"timestamp\": 1717482385,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00079\",\n    \"date\": \"2024-06-04_08-26-25\",\n    \"time_this_iter_s\": 12534.907884597778,\n    \"time_total_s\": 12534.907884597778,\n    \"pid\": 604156,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 12534.907884597778,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"79_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717482385.4187102,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8994905956112852,\n      \"min\": 0.8994905956112852,\n      \"avg\": 0.8994905956112852,\n      \"last\": 0.8994905956112852,\n      \"last-5-avg\": 0.8994905956112852,\n      \"last-10-avg\": 0.8994905956112852\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12534.907884597778,\n      \"min\": 12534.907884597778,\n      \"avg\": 12534.907884597778,\n      \"last\": 12534.907884597778,\n      \"last-5-avg\": 12534.907884597778,\n      \"last-10-avg\": 12534.907884597778\n    },\n    \"time_total_s\": {\n      \"max\": 12534.907884597778,\n      \"min\": 12534.907884597778,\n      \"avg\": 12534.907884597778,\n      \"last\": 12534.907884597778,\n      \"last-5-avg\": 12534.907884597778,\n      \"last-10-avg\": 12534.907884597778\n    },\n    \"time_since_restore\": {\n      \"max\": 12534.907884597778,\n      \"min\": 12534.907884597778,\n      \"avg\": 12534.907884597778,\n      \"last\": 12534.907884597778,\n      \"last-5-avg\": 12534.907884597778,\n      \"last-10-avg\": 12534.907884597778\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430893b86680a0c8ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430893b86680a0c8ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c87b7435900000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c87b7435900000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c87b7435900000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c87b7435900000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c87b7435900000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c87b7435900000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00076\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037365f37365f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"76_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00076_76_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717449321.2146366,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8778409090909091,\n    \"timestamp\": 1717455121,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00076\",\n    \"date\": \"2024-06-04_00-52-01\",\n    \"time_this_iter_s\": 5799.955152750015,\n    \"time_total_s\": 5799.955152750015,\n    \"pid\": 596854,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 5799.955152750015,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"76_alpha=0.9900,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717455121.171822,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8778409090909091,\n      \"min\": 0.8778409090909091,\n      \"avg\": 0.8778409090909091,\n      \"last\": 0.8778409090909091,\n      \"last-5-avg\": 0.8778409090909091,\n      \"last-10-avg\": 0.8778409090909091\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5799.955152750015,\n      \"min\": 5799.955152750015,\n      \"avg\": 5799.955152750015,\n      \"last\": 5799.955152750015,\n      \"last-5-avg\": 5799.955152750015,\n      \"last-10-avg\": 5799.955152750015\n    },\n    \"time_total_s\": {\n      \"max\": 5799.955152750015,\n      \"min\": 5799.955152750015,\n      \"avg\": 5799.955152750015,\n      \"last\": 5799.955152750015,\n      \"last-5-avg\": 5799.955152750015,\n      \"last-10-avg\": 5799.955152750015\n    },\n    \"time_since_restore\": {\n      \"max\": 5799.955152750015,\n      \"min\": 5799.955152750015,\n      \"avg\": 5799.955152750015,\n      \"last\": 5799.955152750015,\n      \"last-5-avg\": 5799.955152750015,\n      \"last-10-avg\": 5799.955152750015\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d74d14517ec3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d74d14517ec3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6a7f484e40000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6a7f484e40000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6a7f484e40000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6a7f484e40000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740b6a7f484e40000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740b6a7f484e40000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00050\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035305f35305f616c7068613d302e393930302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e3530305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"50_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00050_50_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.500_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717122999.0605729,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8375,\n    \"timestamp\": 1717135884,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00050\",\n    \"date\": \"2024-05-31_08-11-24\",\n    \"time_this_iter_s\": 12885.514672279358,\n    \"time_total_s\": 12885.514672279358,\n    \"pid\": 473950,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 12885.514672279358,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"50_alpha=0.9900,feature_maps=128_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717135884.5773048,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8375,\n      \"min\": 0.8375,\n      \"avg\": 0.8375,\n      \"last\": 0.8375,\n      \"last-5-avg\": 0.8375,\n      \"last-10-avg\": 0.8375\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 12885.514672279358,\n      \"min\": 12885.514672279358,\n      \"avg\": 12885.514672279358,\n      \"last\": 12885.514672279358,\n      \"last-5-avg\": 12885.514672279358,\n      \"last-10-avg\": 12885.514672279358\n    },\n    \"time_total_s\": {\n      \"max\": 12885.514672279358,\n      \"min\": 12885.514672279358,\n      \"avg\": 12885.514672279358,\n      \"last\": 12885.514672279358,\n      \"last-5-avg\": 12885.514672279358,\n      \"last-10-avg\": 12885.514672279358\n    },\n    \"time_since_restore\": {\n      \"max\": 12885.514672279358,\n      \"min\": 12885.514672279358,\n      \"avg\": 12885.514672279358,\n      \"last\": 12885.514672279358,\n      \"last-5-avg\": 12885.514672279358,\n      \"last-10-avg\": 12885.514672279358\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccccccccea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cdccccccccccea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c92ac1e0c80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c92ac1e0c80000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c92ac1e0c80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c92ac1e0c80000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c92ac1e0c80000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c92ac1e0c80000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00088\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038385f38385f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"88_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00088_88_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717587890.4543822,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.5909090909090909,\n    \"timestamp\": 1717597774,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00088\",\n    \"date\": \"2024-06-05_16-29-34\",\n    \"time_this_iter_s\": 4737.069535970688,\n    \"time_total_s\": 9883.680524587631,\n    \"pid\": 650308,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 9883.680524587631,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"88_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717597774.1387632,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.6113636363636363,\n      \"min\": 0.5909090909090909,\n      \"avg\": 0.6011363636363636,\n      \"last\": 0.5909090909090909,\n      \"last-5-avg\": 0.6011363636363636,\n      \"last-10-avg\": 0.6011363636363636\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5146.610988616943,\n      \"min\": 4737.069535970688,\n      \"avg\": 4941.840262293816,\n      \"last\": 4737.069535970688,\n      \"last-5-avg\": 4941.840262293816,\n      \"last-10-avg\": 4941.840262293816\n    },\n    \"time_total_s\": {\n      \"max\": 9883.680524587631,\n      \"min\": 5146.610988616943,\n      \"avg\": 7515.145756602287,\n      \"last\": 9883.680524587631,\n      \"last-5-avg\": 7515.145756602287,\n      \"last-10-avg\": 7515.145756602287\n    },\n    \"time_since_restore\": {\n      \"max\": 9883.680524587631,\n      \"min\": 5146.610988616943,\n      \"avg\": 7515.145756602287,\n      \"last\": 9883.680524587631,\n      \"last-5-avg\": 7515.145756602287,\n      \"last-10-avg\": 7515.145756602287\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890a704794a90e33f94869452946807680d4308e9a28b2ebae8e23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430890a704794a90e33f94869452946807680d4308e9a28b2ebae8e23f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b41a9c69c000004740b28111cd1c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b41a9c69c000004740b28111cd1c0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b41a9c69c000004740c34dd71b6e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b41a9c69c000004740c34dd71b6e0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b41a9c69c000004740c34dd71b6e0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b41a9c69c000004740c34dd71b6e0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00077\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303037375f37375f616c7068613d302e383530302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e3930305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"77_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00077_77_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.900_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717455123.8967602,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8710359408033824,\n    \"timestamp\": 1717464011,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00077\",\n    \"date\": \"2024-06-04_03-20-11\",\n    \"time_this_iter_s\": 8887.275920152664,\n    \"time_total_s\": 8887.275920152664,\n    \"pid\": 598965,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959e020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 8887.275920152664,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"77_alpha=0.8500,feature_maps=64_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_a76486af,tau=0.9000\"\n  },\n  \"last_result_time\": 1717464011.174777,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8710359408033824,\n      \"min\": 0.8710359408033824,\n      \"avg\": 0.8710359408033824,\n      \"last\": 0.8710359408033824,\n      \"last-5-avg\": 0.8710359408033824,\n      \"last-10-avg\": 0.8710359408033824\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 8887.275920152664,\n      \"min\": 8887.275920152664,\n      \"avg\": 8887.275920152664,\n      \"last\": 8887.275920152664,\n      \"last-5-avg\": 8887.275920152664,\n      \"last-10-avg\": 8887.275920152664\n    },\n    \"time_total_s\": {\n      \"max\": 8887.275920152664,\n      \"min\": 8887.275920152664,\n      \"avg\": 8887.275920152664,\n      \"last\": 8887.275920152664,\n      \"last-5-avg\": 8887.275920152664,\n      \"last-10-avg\": 8887.275920152664\n    },\n    \"time_since_restore\": {\n      \"max\": 8887.275920152664,\n      \"min\": 8887.275920152664,\n      \"avg\": 8887.275920152664,\n      \"last\": 8887.275920152664,\n      \"last-5-avg\": 8887.275920152664,\n      \"last-10-avg\": 8887.275920152664\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080d84ecc386dfeb3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080d84ecc386dfeb3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c15ba3515a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c15ba3515a0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c15ba3515a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c15ba3515a0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740c15ba3515a0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740c15ba3515a0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059535030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c956f626a6563746976655f35623364665f30303030305f305f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f61373634383661662c7461753d302e313030305f323032342d30352d32335f31362d30342d3234948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"8005958b020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c044154616e948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944bd143020c01948c05616c70686194859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c136174616e2e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944740000000000000008594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.1,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"a76486af\"\n    ],\n    \"tau\": 0.1\n  },\n  \"experiment_tag\": \"0_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"relative_logdir\": \"objective_5b3df_00000_0_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_a76486af,tau=0.1000_2024-05-23_16-04-24\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1716473067.0787086,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"trial_id\": \"5b3df_00000\"\n  },\n  \"last_result_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00056\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303035365f35365f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e353030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.99,\n    \"tau\": 0.5,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.5\n  },\n  \"experiment_tag\": \"56_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00056_56_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717194236.0065565,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7672413793103449,\n    \"timestamp\": 1717205581,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00056\",\n    \"date\": \"2024-06-01_03-33-01\",\n    \"time_this_iter_s\": 5977.058048009872,\n    \"time_total_s\": 11345.73322224617,\n    \"pid\": 501169,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.99,\n      \"tau\": 0.5,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 11345.73322224617,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"56_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.5000\"\n  },\n  \"last_result_time\": 1717205581.743813,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7672413793103449,\n      \"min\": 0.7574300699300699,\n      \"avg\": 0.7623357246202074,\n      \"last\": 0.7672413793103449,\n      \"last-5-avg\": 0.7623357246202074,\n      \"last-10-avg\": 0.7623357246202074\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 5977.058048009872,\n      \"min\": 5368.675174236298,\n      \"avg\": 5672.866611123085,\n      \"last\": 5977.058048009872,\n      \"last-5-avg\": 5672.866611123085,\n      \"last-10-avg\": 5672.866611123085\n    },\n    \"time_total_s\": {\n      \"max\": 11345.73322224617,\n      \"min\": 5368.675174236298,\n      \"avg\": 8357.204198241234,\n      \"last\": 11345.73322224617,\n      \"last-5-avg\": 8357.204198241234,\n      \"last-10-avg\": 8357.204198241234\n    },\n    \"time_since_restore\": {\n      \"max\": 11345.73322224617,\n      \"min\": 5368.675174236298,\n      \"avg\": 8357.204198241234,\n      \"last\": 11345.73322224617,\n      \"last-5-avg\": 8357.204198241234,\n      \"last-10-avg\": 8357.204198241234\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f696bfcdd3ce83f94869452946807680d4308ddd308cb3d8de83f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089f696bfcdd3ce83f94869452946807680d4308ddd308cb3d8de83f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4f8acd83800004740b7590edc3c0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4f8acd83800004740b7590edc3c0000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4f8acd83800004740c628ddda3a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4f8acd83800004740c628ddda3a0000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b4f8acd83800004740c628ddda3a0000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b4f8acd83800004740c628ddda3a0000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00080\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303038305f38305f616c7068613d302e393930302c666561747572655f6d6170733d36345f3132382c68696464656e5f6c61796572733d3132385f36342c6c723d302e303030312c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e393030305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.0001,\n    \"alpha\": 0.99,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.99,\n    \"feature_maps\": [\n      64,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      64\n    ],\n    \"lr\": 0.0001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"80_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00080_80_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717482387.2867205,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.8395915678524376,\n    \"timestamp\": 1717496589,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 1,\n    \"trial_id\": \"5b3df_00080\",\n    \"date\": \"2024-06-04_12-23-09\",\n    \"time_this_iter_s\": 14202.643909215927,\n    \"time_total_s\": 14202.643909215927,\n    \"pid\": 608534,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.0001,\n      \"alpha\": 0.99,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        64,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        64\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 14202.643909215927,\n    \"iterations_since_restore\": 1,\n    \"experiment_tag\": \"80_alpha=0.9900,feature_maps=64_128,hidden_layers=128_64,lr=0.0001,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717496589.9326084,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.8395915678524376,\n      \"min\": 0.8395915678524376,\n      \"avg\": 0.8395915678524376,\n      \"last\": 0.8395915678524376,\n      \"last-5-avg\": 0.8395915678524376,\n      \"last-10-avg\": 0.8395915678524376\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": true,\n      \"avg\": true,\n      \"last\": true,\n      \"last-5-avg\": true,\n      \"last-10-avg\": true\n    },\n    \"training_iteration\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    },\n    \"time_this_iter_s\": {\n      \"max\": 14202.643909215927,\n      \"min\": 14202.643909215927,\n      \"avg\": 14202.643909215927,\n      \"last\": 14202.643909215927,\n      \"last-5-avg\": 14202.643909215927,\n      \"last-10-avg\": 14202.643909215927\n    },\n    \"time_total_s\": {\n      \"max\": 14202.643909215927,\n      \"min\": 14202.643909215927,\n      \"avg\": 14202.643909215927,\n      \"last\": 14202.643909215927,\n      \"last-5-avg\": 14202.643909215927,\n      \"last-10-avg\": 14202.643909215927\n    },\n    \"time_since_restore\": {\n      \"max\": 14202.643909215927,\n      \"min\": 14202.643909215927,\n      \"avg\": 14202.643909215927,\n      \"last\": 14202.643909215927,\n      \"last-5-avg\": 14202.643909215927,\n      \"last-10-avg\": 14202.643909215927\n    },\n    \"iterations_since_restore\": {\n      \"max\": 1,\n      \"min\": 1,\n      \"avg\": 1,\n      \"last\": 1,\n      \"last-5-avg\": 1,\n      \"last-10-avg\": 1\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308018ebd22efddea3f9486945294612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059589000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452948c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308018ebd22efddea3f9486945294612e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529488612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529488612e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cbbd526b9e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cbbd526b9e0000612e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cbbd526b9e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cbbd526b9e0000612e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944740cbbd526b9e0000612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944740cbbd526b9e0000612e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452944b01612e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059523000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452944b01612e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"], ["{\n  \"stub\": false,\n  \"trainable_name\": \"objective\",\n  \"trial_id\": \"5b3df_00095\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059536030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c136578706572696d656e745f6469725f6e616d65948c0b677269645f736561726368948c0e747269616c5f6469725f6e616d65948c966f626a6563746976655f35623364665f30303039355f39355f616c7068613d302e383530302c666561747572655f6d6170733d3132385f3132382c68696464656e5f6c61796572733d3132385f3132382c6c723d302e303031302c737572726f676174655f677261643d7265665f70685f64376664643536652c7461753d302e39305f323032342d30352d32335f31362d30342d3235948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468168c1273796e635f6f6e5f636865636b706f696e7494681675628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c1a2f686f6d652f656c656f6e6f72612f7261795f726573756c747394681768008c115f46696c6573797374656d53796e6365729493942981947d94286819682068114d2c0168124d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e75628c0a5f74696d657374616d70948c13323032342d30352d32335f31362d30342d32349475622e\"\n  },\n  \"config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059593020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a681a680a9394737586948652302e\"\n    }\n  },\n  \"_Trial__unresolved_config\": {\n    \"lr\": 0.001,\n    \"alpha\": 0.85,\n    \"tau\": 0.9,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ]\n  },\n  \"evaluated_params\": {\n    \"alpha\": 0.85,\n    \"feature_maps\": [\n      128,\n      128\n    ],\n    \"hidden_layers\": [\n      128,\n      128\n    ],\n    \"lr\": 0.001,\n    \"surrogate_grad\": [\n      \"__ref_ph\",\n      \"d7fdd56e\"\n    ],\n    \"tau\": 0.9\n  },\n  \"experiment_tag\": \"95_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 2,\n    \"mean_accuracy\": 0.8\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"800595ba000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d947d94288c0343505594473ff00000000000008c0347505594473ff000000000000075618c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"TERMINATED\",\n  \"relative_logdir\": \"objective_5b3df_00095_95_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.90_2024-05-23_16-04-25\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}", "{\n  \"start_time\": 1717680122.6957543,\n  \"num_failures\": 0,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"last_result\": {\n    \"mean_accuracy\": 0.7426136363636363,\n    \"timestamp\": 1717690549,\n    \"checkpoint_dir_name\": null,\n    \"done\": true,\n    \"training_iteration\": 2,\n    \"trial_id\": \"5b3df_00095\",\n    \"date\": \"2024-06-06_18-15-49\",\n    \"time_this_iter_s\": 4323.600244998932,\n    \"time_total_s\": 10426.683374881744,\n    \"pid\": 685613,\n    \"hostname\": \"cicciarella-alienware\",\n    \"node_ip\": \"147.162.13.167\",\n    \"config\": {\n      \"lr\": 0.001,\n      \"alpha\": 0.85,\n      \"tau\": 0.9,\n      \"feature_maps\": [\n        128,\n        128\n      ],\n      \"hidden_layers\": [\n        128,\n        128\n      ],\n      \"surrogate_grad\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595a6020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b014b044b13430c7400a0017c008800a1025300944e85948c0b466173745369676d6f6964948c056170706c799486948c01789485948c702f686f6d652f656c656f6e6f72612f446f63756d656e74732f5061706572732f4c6561726e65645f5370696b655f456e636f64696e672f656e76736e6e2f6c69622f707974686f6e332e31302f736974652d7061636b616765732f736e6e746f7263682f737572726f676174652e7079948c05696e6e6572944b9543020c01948c05736c6f706594859429749452947d94288c0b5f5f7061636b6167655f5f948c08736e6e746f726368948c085f5f6e616d655f5f948c12736e6e746f7263682e737572726f67617465948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c94939429529485947494529468008c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1b666173745f7369676d6f69642e3c6c6f63616c733e2e696e6e6572948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493944b198594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680a8c12736e6e746f7263682e737572726f6761746594680a9394737586948652302e\"\n      }\n    },\n    \"time_since_restore\": 10426.683374881744,\n    \"iterations_since_restore\": 2,\n    \"experiment_tag\": \"95_alpha=0.8500,feature_maps=128_128,hidden_layers=128_128,lr=0.0010,surrogate_grad=ref_ph_d7fdd56e,tau=0.9000\"\n  },\n  \"last_result_time\": 1717690549.3827474,\n  \"metric_analysis\": {\n    \"mean_accuracy\": {\n      \"max\": 0.7512175324675325,\n      \"min\": 0.7426136363636363,\n      \"avg\": 0.7469155844155844,\n      \"last\": 0.7426136363636363,\n      \"last-5-avg\": 0.7469155844155844,\n      \"last-10-avg\": 0.7469155844155844\n    },\n    \"done\": {\n      \"max\": true,\n      \"min\": false,\n      \"avg\": 0.5,\n      \"last\": true,\n      \"last-5-avg\": 0.5,\n      \"last-10-avg\": 0.5\n    },\n    \"training_iteration\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 6103.0831298828125,\n      \"min\": 4323.600244998932,\n      \"avg\": 5213.341687440872,\n      \"last\": 4323.600244998932,\n      \"last-5-avg\": 5213.341687440872,\n      \"last-10-avg\": 5213.341687440872\n    },\n    \"time_total_s\": {\n      \"max\": 10426.683374881744,\n      \"min\": 6103.0831298828125,\n      \"avg\": 8264.883252382278,\n      \"last\": 10426.683374881744,\n      \"last-5-avg\": 8264.883252382278,\n      \"last-10-avg\": 8264.883252382278\n    },\n    \"time_since_restore\": {\n      \"max\": 10426.683374881744,\n      \"min\": 6103.0831298828125,\n      \"avg\": 8264.883252382278,\n      \"last\": 10426.683374881744,\n      \"last-5-avg\": 8264.883252382278,\n      \"last-10-avg\": 8264.883252382278\n    },\n    \"iterations_since_restore\": {\n      \"max\": 2,\n      \"min\": 1,\n      \"avg\": 1.5,\n      \"last\": 2,\n      \"last-5-avg\": 1.5,\n      \"last-10-avg\": 1.5\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"mean_accuracy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e627c459f909e83f94869452946807680d4308c3da37ac7dc3e73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e627c459f909e83f94869452946807680d4308c3da37ac7dc3e73f9486945294652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288988652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059524000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288988652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b7d715480000004740b0e399a9a80000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b7d715480000004740b0e399a9a80000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b7d715480000004740c45d5778d40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b7d715480000004740c45d5778d40000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b7d715480000004740c45d5778d40000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b7d715480000004740c45d5778d40000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b014b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059526000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b02652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"]], "runner_data": {"_earliest_stopping_actor": 1825865.262198367, "_actor_cleanup_timeout": 600, "_actor_force_cleanup_timeout": 10, "_reuse_actors": false, "_buffer_length": 1, "_buffer_min_time_s": 0.0, "_buffer_max_time_s": 100.0, "_max_pending_trials": 200, "_metric": "mean_accuracy", "_total_time": 1210221.4046018124, "_iteration": 12101077, "_has_errored": true, "_fail_fast": false, "_print_trial_errors": true, "_cached_trial_decisions": {}, "_queued_trial_decisions": {}, "_should_stop_experiment": false, "_stopper": {"_type": "CLOUDPICKLE_FALLBACK", "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"}, "_start_time": 1716473064.8211336, "_session_str": "2024-05-23_16-04-24", "_checkpoint_period": "auto", "_trial_checkpoint_config": {"_type": "CLOUDPICKLE_FALLBACK", "value": "800595f2000000000000008c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e6494898c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"}, "_resumed": false}, "stats": {"start_time": 1716473064.8211336}}